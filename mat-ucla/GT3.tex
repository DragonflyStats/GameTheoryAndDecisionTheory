
\documentclass[]{report}
\voffset=-1.5cm
\oddsidemargin=0.0cm
\textwidth = 480pt


\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{multicol}
%\usepackage[paperwidth=21cm, paperheight=29.8cm]{geometry}
%\usepackage[angle=0,scale=1,color=black,hshift=-0.4cm,vshift=15cm]{background}
%\usepackage{multirow}
\usepackage{enumerate}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{color}
\usepackage{multirow}
\usepackage{eurosym}
\usepackage{framed}

%\input def.tex
%\input dsdef.tex
%\input rgb.tex

%\newcommand \la{\lambda}
%\newcommand \al{a}
%\newcommand \be{b}
\newcommand \x{\overline{x}}
\newcommand \y{\overline{y}}
\begin{document}


%=======================================================%

\section{3. The Principle of Indifference.}
For a matrix game with m × n matrix A, if Player I uses the mixed strategy p =
$(p1, \ldots,pm)$
T and Player II uses column j, Player I’s average payoff is m
i=1 piaij . If V is
the value of the game, an optimal strategy, p, for I is characterized by the property that
Player I’s average payoff is at least V no matter what column j Player II uses, i.e.

m
i=1
piaij \geq V for all j = 1, . . . , n. (1)
Similarly, a strategy q = (q1, \ldots,qn)
T is optimal for II if and only if

n
j=1
aij qj \leq V for all i = 1, . . . , m. (2)
When both players use their optimal strategies the average payoff, 
i

j piaij qj , is exactly
V . This may be seen from the inequalities
V = 
n
j=1
V qj \leq 
n
j=1
(

m
i=1
piaij )qj = 
m
i=1

n
j=1
piaij qj
= 
m
i=1
pi(

n
j=1
aij qj ) \leq 
m
i=1
piV = V.
(3)
Since this begins and ends with V we must have equality throughout.

%=======================================================%
\subsection{3.1 The Equilibrium Theorem.} The following simple theorem – the Equilibrium
Theorem – gives conditions for equality to be achieved in (1) for certain values of j, and
in (2) for certain values of i.
%=======================================================%
Theorem 3.1. Consider a game with m×n matrix A and value V . Let p = (p1, \ldots,pm)
T
be any optimal strategy for I and q = (q1, \ldots,qn)
T be any optimal strategy for II. Then

n
j=1
aij qj = V for all i for which pi > 0 (4)
and

m
i=1
piaij = V for all j for which qj > 0. (5)
Proof. Suppose there is a k such that pk > 0 and n
j=1 akj qj = V . Then from (2),
n
j=1 akj qj < V . But then from (3) with equality throughout
V = 
m
i=1
pi(

n
j=1
aij qj ) < 
m
i=1
piV = V.
II – 18
The inequality is strict since it is strict for the kth term of the sum. This contradiction
proves the first conclusion. The second conclusion follows analogously.
Another way of stating the first conclusion of this theorem is: If there exists an optimal
strategy for I giving positive probability to row i, then every optimal strategy of II gives
I the value of the game if they uses row i.

%=======================================================%
This theorem is useful in certain classes of games for helping direct us toward the
solution. The procedure this theorem suggests for Player 1 is to try to find a solution to
the set of equations (5) formed by those j for which you think it likely that qj > 0. One
way of saying this is that Player 1 searches for a strategy that makes Player 2 indifferent
as to which of the (good) pure strategies to use. Similarly, Player 2 should play in such a
way to make Player 1 indifferent among their (good) strategies. This is called the \textbf{Principle
of Indifference.}

%=======================================================%
\subsection{Example.} As an example of this consider the game of Odd-or-Even in which both
players simultaneously call out one of the numbers zero, one, or two. The matrix is
Even
Odd
⎛
⎝
0 1 −2
1 −2 3
−2 3 −4
⎞
⎠
Again it is difficult to guess who has the advantage. If we play the game a few times we
might become convinced that Even’s optimal strategy gives positive weight (probability)
to each of the columns. If this assumption is true, Odd should play to make Player 2
indifferent; that is, Odd’s optimal strategy p must satisfy
\begin{eqnarray}
p2 − 2p3 &= V\\
p1 − 2p2 + 3p3 &= V\\
−2p1 + 3p2 − 4p3 &= V,\\
\end{eqnarray}
(6)
for some number, V — three equations in four unknowns. A fourth equation that must be
satisfied is
\[p1 + p2 + p3 = 1\]. (7)

This gives four equations in four unknowns. This system of equations is solved as follows.
First we work with (6); add the first equation to the second.
\[p1 − p2 + p3 = 2V\] (8)
Then add the second equation to the third.
\[−p1 + p2 − p3 = 2V\] (9)
Taken together (8) and (9) imply that V = 0. Adding (7) to (9), we find 2p2 = 1, so that
p2 = 1/2. The first equation of (6) implies p3 = 1/4 and (7) implies p1 = 1/4. Therefore
p = (1/4, 1/2, 1/4)T (10)
%%II – 19
is a strategy for I that keeps their average gain to zero no matter what II does. Hence the
value of the game is at least zero, and V = 0 if our assumption that II’s optimal strategy
gives positive weight to all columns is correct. To complete the solution, we note that if the
optimal p for I gives positive weight to all rows, then II’s optimal strategy q must satisfy
the same set of equations (6) and (7) with p replaced by q (because the game matrix here
is symmetric). Therefore,
$q = (1/4, 1/2, 1/4)^T$ 
is a strategy for II that keeps their average loss to zero no matter what I does. Thus the
value of the game is zero and (10) and (11) are optimal for I and II respectively. The game
is fair.
%=======================================================%
\subsection{3.2 Nonsingular Game Matrices.} Let us extend the method used to solve this
example to arbitrary nonsingular square matrices. Let the game matrix A be m × m,
and suppose that A is nonsingular. Assume that I has an optimal strategy giving positive
weight to each of the rows. (This is called the all-strategies-active case.) Then by the
principle of indifference, every optimal strategy q for II satisfies (4), or

m
j=1
aij qj = V for i = 1, \ldots,m. (12)

This is a set of m equations in m unknowns, and since A is nonsingular, we may solve
for the qi. Let us write this set of equations in vector notation using q to represent the
column vector of II’s strategy, and 1 = (1, 1, \ldots, 1)T to represent the column vector of all
1’s:
Aq = V 1 (13)
We note that V cannot be zero since (13) would imply that A was singular. Since A is
non-singular, A−1 exists. Multiplying both sides of (13) on the left by A−1 yields
q = V A−11. (14)
If the value of V were known, this would give the unique optimal strategy for II. To find
V , we may use the equation m
j=1 qj = 1, or in vector notation 1Tq = 1. Multiplying both
sides of (14) on the left by 1T yields 1 = 1Tq = V 1TA−11. This shows that 1TA−11 cannot
be zero so we can solve for V :
V = 1/1
TA−11. (15)
The unique optimal strategy for II is therefore
q = A−11/1
TA−11. (16)
However, if some component, qj , turns out to be negative, then our assumption that I has
an optimal strategy giving positive weight to each row is false.
However, if $q_j \geq 0$ for all j, we may seek an optimal strategy for I by the same method.
The result would be
p
T = 1
TA−1/1
T
A−11. (17)
II – 20
%=========================================================%
\begin{itemize}
\item Now, if in addition $p_i \geq 0$ for all $i$, then both p and q are optimal since both guarantee an
average payoff of V no matter what the other player does.
\item Note that we do not require the
pi to be strictly positive as was required by our original “all-strategies-active” assumption.
We summarize this discussion as a theorem.
\end{itemize}
Theorem 3.2. Assume the square matrix A is nonsingular and 1TA−11 = 0. Then the
game with matrix A has value V = 1/1TA−11 and optimal strategies pT = V 1TA−1 and
q = V A−11, provided both $p \geq 0$ and $q \geq 0$.
%====================================================================%
If the value of a game is zero, this method cannot work directly since (13) implies
that A is singular. However, the addition of a positive constant to all entries of the matrix
to make the value positive, may change the game matrix into being nonsingular. The
previous example of Odd-or-Even is a case in point. The matrix is singular so it would
seem that the above method would not work. Yet if 1, say, were added to each entry of
the matrix to obtain the matrix A below, then A is nonsingular and we may apply the
above method. Let us carry through the computations. By some method or another A−1
is obtained.
A =
⎛
⎝
1 2 −1
2 −1 4
−1 4 −3
⎞
⎠ A−1 = 1
16
⎛
⎝
13 −2 −7
−246
−765
⎞
⎠
Then 1TA−11 , the sum of the elements of A−1, is found to be 1, so from (15), V = 1.
Therefore, we compute pT = 1TA−1 = (1/4, 1/2, 1/4)T, and q = A−11 = (1/4, 1/2, 1/4)T.
Since both are nonnegative, both are optimal and 1 is the value of the game with matrix
A.
%===========================================================%
\begin{itemize}
\item What do we do if either p or q has negative components? A complete answer to
questions of this sort is given in the comprehensive theorem of Shapley and Snow (1950).
\item This theorem shows that an arbitrary $m \times n$ matrix game whose value is not zero may be
solved by choosing some suitable square submatrix A, and applying the above methods
and checking that the resulting optimal strategies are optimal for the whole matrix, A.
\item Optimal strategies obtained in this way are called basic, and it is noted that every optimal
strategy is a probability mixture of basic optimal strategies. Such a submatrix, A, is called
an active submatrix of the game.See Karlin (1959, Vol. I, Section 2.4) for a discussion and
proof.
\item  The problem is to determine which square submatrix to use. The simplex method
of linear programming is simply an efficient method not only for solving equations of the
form (13), but also for finding which square submatrix to use. This is described in Section
4.4.
\end{itemize}
%============================================================%
\subsection{3.3 Diagonal Games.} We apply these ideas to the class of diagonal games - games
whose game matrix A is square and diagonal,
A =
⎛
⎜⎜⎝
d1 0 ... 0
0 d2 ... 0 .
.
. .
.
. ... .
.
.
0 0 ... dm
⎞
⎟⎟⎠
(18)
II – 21
Suppose all diagonal terms are positive, di > 0 for all i. (The other cases are treated in
Exercise 2.) One may apply Theorem 3.2 to find the solution, but it is as easy to proceed
directly. The set of equations (12) becomes
pidi = V for i = 1, \ldots,m (19)
whose solution is simply
pi = V /di for i = 1, . . . , m. (20)
To find V , we sum both sides over i to find
1 = V 
m
i=1
1/di or V = (
m
i=1
1/di)
−1. (21)
Similarly, the equations for Player II yield
qi = V /di for i = 1, \ldots,m. (22)
Since V is positive from (21), we have pi > 0 and qi > 0 for all i, so that (20) and (22)
give optimal strategies for I and II respectively, and (21) gives the value of the game.
As an example, consider the game with matrix C.
C =
⎛
⎜⎝
1000
0200
0030
0004
⎞
⎟⎠
From (20) and (22) the optimal strategy is proportional to the reciprocals of the diagonal
elements. The sum of these reciprocals is $1 + 1/2+1/3+1/4 = 25/12$. Therefore, the
value is V = 12/25, and the optimal strategies are $p = q = (12/25, 6/25, 4/25, 3/25)^T$.
%==================================================================%
\subsection{3.4 Triangular Games.} Another class of games for which the equations (12) are
easy to solve are the games with triangular matrices - matrices with zeros above or below
the main diagonal. Unlike for diagonal games, the method does not always work to solve
triangular games because the resulting p or q may have negative components. Nevertheless,
it works often enough to merit special mention. Consider the game with triangular matrix
T .
T =
⎛
⎜⎝
1 −2 3 −4
0 1 −2 3
001 −2
0001
⎞
⎟⎠
The equations (12) become
p1 = V
−2p1 + p2 = V
3p1 − 2p2 + p3 = V
−4p1 + 3p2 − 2p3 + p4 = V .
II – 22
These equations may be solved one at a time from the top down to give
p1 = V p2 = 3V p3 = 4V p4 = 4V.
Since pi = 1, we find V = 1/12 and p = (1/12, 1/4, 1/3, 1/3). The equations for the q’s
are
q1 − 2q2 + 3q3 − 4q4 = V
q2 − 2q3 + 3q4 = V
q3 − 2q4 = V
q4 = V .
The solution is
q1 = 4V q2 = 4V q3 = 3V q4 = V.
Since the p’s and q’s are non-negative, V = 1/12 is the value, p = (1/12, 1/4, 1/3, 1/3) is
optimal for I, and q = (1/3, 1/3, 1/4, 1/12) is optimal for II.
%======================================================================%
\section{3.5 Symmetric Games.} A game is symmetric if the rules do not distinguish between
the players. For symmetric games, both players have the same options (the game matrix
is square), and the payoff if I uses i and II uses j is the negative of the payoff if I uses j
and II uses i. This means that the game matrix should be skew-symmetric: A = −AT,
or aij = −aji for all i and j.
\begin{framed}
Definition 3.1. A finite game is said to be symmetric if its game matrix is square and
skew-symmetric.
\end{framed}
Speaking more generally, we may say that a game is symmetric if after some rearrangement
of the rows or columns the game matrix is skew-symmetric.
%=======================================================================%
The game of paper-scissors-rock is an example. In this game, Players I and II simultaneously
display one of the three objects: paper, scissors, or rock. If they both choose the
same object to display, there is no payoff. If they choose different objects, then scissors win
over paper (scissors cut paper), rock wins over scissors (rock breaks scissors), and paper
wins over rock (paper covers rock). If the payoff upon winning or losing is one unit, then
the matrix of the game is as follows.
%=======================================================================%
II
I
⎛
⎝
paper scissors rock
paper 0 −1 1
scissors 1 0 −1
rock −1 10
⎞
⎠
This matrix is skew-symmetric so the game is symmetric. The diagonal elements of
the matrix are zero. This is true of any skew-symmetric matrix, since aii = −aii implies
aii = 0 for all i.
A contrasting example is the game of matching pennies. The two players simultaneously
choose to show a penny with either the heads or the tails side facing up. One of the
II – 23
players, say Player I, wins if the choices match. The other player, Player II, wins if the
choices differ. Although there is a great deal of symmetry in this game, we do not call it
a symmetric game. Its matrix is
II
I

heads tails
heads 1 −1
tails −1 1
This matrix is not skew-symmetric.
We expect a symmetric game to be fair, that is to have value zero, V = 0. This is
indeed the case.
Theorem 3.3. A finite symmetric game has value zero. Any strategy optimal for one
player is also optimal for the other.
Proof. Let p be an optimal strategy for I. If II uses the same strategy the average payoff
is zero, because
p
TAp = 

piaijpj = 

pi(−aji)pj = −


pjajipi = −p
T
Ap (23)
implies that pTAp = 0. This shows that the value V \leq 0. A symmetric argument shows
that $V \geq 0$. Hence V = 0. Now suppose p is optimal for I. Then m
i=1 piaij \geq 0 for all
j. Hence m
j=1 aijpj = −m
j=1 pjaji \leq 0 for all i, so that p is also optimal for II. By
symmetry, if q is optimal for II, it is optimal for I also.
%=====================================================================%
\section{Mendelsohn Games.}
 (N. S. Mendelsohn (1946)) In Mendelsohn games, two players
simultaneously choose a positive integer. Both players want to choose an integer larger
but not too much larger than the opponent. Here is a simple example. The players choose
an integer between 1 and 100. If the numbers are equal there is no payoff. The player that
chooses a number one larger than that chosen by their opponent wins 1. The player that
chooses a number two or more larger than their opponent loses 2. Find the game matrix
and solve the game.
Solution. The payoff matrix is
⎛
⎜⎜⎜⎜⎜⎜⎝
12345 ···
1 0 −1222 ···
2 10 −122 ···
3 −210 −1 2 ···
4 −2 −210 −1 ···
5 −2 −2 −210 ··· .
.
. .
.
. ...
⎞
⎟⎟⎟⎟⎟⎟⎠
(24)
The game is symmetric so the value is zero and the players have identical optimal strategies.
We see that row 1 dominates rows 4, 5, 6,... so we may restrict attention to the upper left
II – 24
3 × 3 submatrix. We suspect that there is an optimal strategy for I with p1 > 0, p2 > 0
and p3 > 0. If so, it would follow from the principle of indifference (since q1 = p1 > 0,
q2 = p2 > 0 q3 = p3 > 0 is optimal for II) that
p2 − 2p3 = 0
−p1 + p3 = 0
2p1 − p2 = 0. (25)
We find p2 = 2p3 and p1 = p3 from the first two equations, and the third equation is
redundant. Since p1 + p2 + p3 = 1, we have 4p3 = 1; so p1 = 1/4, p2 = 1/2, and p3 = 1/4.
Since p1, p2 and p3 are positive, this gives the solution: p = q = (1/4, 1/2, 1/4, 0, 0,...)
T is
optimal for both players.
%================================================================================%
\subsection{3.6 Invariance.} 
\begin{itemize}
\item Consider the game of matching pennies: Two players simultaneously
choose heads or tails. Player I wins if the choices match and Player II wins otherwise.
\item There doesn’t seem to be much of a reason for either player to choose heads instead of
tails. In fact, the problem is the same if the names of heads and tails are interchanged. In
other words, the problem is invariant under interchanging the names of the pure strategies.
\item 
In this section, we make the notion of invariance precise. We then define the notion of
an invariant strategy and show that in the search for a minimax strategy, a player may
restrict attention to invariant strategies. 
\item Use of this result greatly simplifies the search for
minimax strategies in many games. In the game of matching pennies for example, there is
only one invariant strategy for either player, namely, choose heads or tails with probability
1/2 each. 
\item 
Therefore this strategy is minimax without any further computation.
We look at the problem from Player II’s viewpoint. Let Y denote the pure strategy
space of Player II, assumed finite. A transformation, g of Y into Y is said to be onto Y
if the range of g is the whole of Y , that is, if for every y1 ∈ Y there is y2 ∈ Y such that
g(y2) = y1. A transformation, g, of Y into itself is said to be one-to-one if g(y1) = g(y2)
implies y1 = y2.
\end{itemize}
%===============================================================================%
Definition 3.2. Let G = (X, Y, A) be a finite game, and let g be a one-to-one transformation
of Y onto itself. The game G is said to be invariant under g if for every x ∈ X
there is a unique x ∈ X such that
A(x, y) = A(x
, g(y)) for all $ y \in Y$. (26)
The requirement that x be unique is not restrictive, for if there were another point
x ∈ X such that
A(x, y) = A(x, g(y)) for all $ y \in Y$, (27)
then, we would have A(x
, g(y)) = A(x, g(y)) for all $ y \in Y$, and since g is onto,
A(x
, y) = A(x, y) for all $ y \in Y$. (28)
Thus the strategies x and x have identical payoffs and we could remove one of them from
X without changing the problem at all.
II – 25
To keep things simple, we assume without loss of generality that all duplicate pure
strategies have been eliminated. That is, we assume
A(x
, y) = A(x, y) for all $ y \in Y$implies that x = x, and
A(x, y
) = A(x, y) for all $ x \in X$implies that y = y. (29)
Unicity of x in Definition 3.2 follows from this assumption.
The given x in Definition 3.2 depends on g and x only. We denote it by x = g(x).
We may write equation (26) defining invariance as
A(x, y) = A(g(x), g(y)) for all $ x \in X$and $ y \in Y$. (26
)
The mapping g is a one-to-one transformation of X since if g(x1) = g(x2), then
A(x1, y) = A(g(x1), g(y)) = A(g(x2), g(y)) = A(x2, y) (30)
for all $ y \in Y$, which implies x1 = x2 from assumption (29). Therefore the inverse, g−1, of
g, defined by g−1(g(x)) = g(g−1(x)) = x, exists. Moreover, any one-to-one transformation
of a finite set is automatically onto, so g is a one-to-one transformation of X onto itself.
%==============================================================%
Lemma 1. If a finite game, G = (X, Y, A), is invariant under a one-to-one transformation,
g, then G is also invariant under g−1.
Proof. We are given A(x, y) = A(g(x), g(y)) for all $ x \in X$and all $ y \in Y$. Since true for
all x and y, it is true if y is replaced by g−1(y) and x is replaced by g−1(x). This gives
A(g−1(x), g−1(y)) = A(x, y) for all $ x \in X$and all $ y \in Y$. This shows that G is invariant
under g−1.
Lemma 2. If a finite game, G = (X, Y, A), is invariant under two one-to-one transformations,
g1 and g2, then G is also invariant under under the composition transformation,
g2g1, defined by g2g1(y) = g2(g1(y)).
Proof. We are given A(x, y) = A(g1(x), g1(y)) for all $ x \in X$and all $ y \in Y$, and A(x, y) =
A(g2(x), g2(y)) for all $ x \in X$and all $ y \in Y$. Therefore,
A(x, y) = A(g2(g1(x)), g2(g1(y))) = A(g2(g1(x)), g2g1(y)) for all $ y \in Y$and x ∈ X.
(31)
which shows that G is invarant under g2g1.
Furthermore, these proofs show that
g2g1 = g2 g1, and g−1 = g−1. (32)
Thus the class of transformations, g on Y , under which the problem is invariant forms a
group, G, with composition as the multiplication operator. The identity element, e of the
group is the identity transformation, e(y) = y for all $ y \in Y$. The set, G of corresponding
transformations g on X is also a group, with identity e(x) = x for all x ∈ X. Equations
(32) say that G is isomorphic to G; as groups, they are indistinguishable.
This shows that we could have analyzed the problem from Player I’s viewpoint and
arrived at the same groups G and G.
II – 26
%==========================================================%
\subsection{Definition 3.3.} A finite game G = (X, Y, A) is said to be invariant under a group, G of
transformations, if (26
) holds for all $g \in G$.
We now define what it means for a mixed strategy, q, for Player II to be invariant
under a group G. Let m denote the number of elements in X and n denote the number of
elements in Y .
%==========================================================%
\subsection{Definition 3.4.} Given that a finite game G = (X, Y, A) is invariant under a group, G,
of one-to-one transformations of Y , a mixed strategy, q = (q(1), \ldots,q(n)), for Player II is
said to be invariant under G if
q(g(y)) = q(y) for all $ y \in Y$and all $g \in G$. (33)
Similarly a mixed strategy p = (p(1), \ldots,p(m)), for Player I is said to be invariant under
G (or G) if
p(g(x)) = p(x) for all $ x \in X$and all $g \in G$. (34)
Two points y1 and y2 in Y are said to be equivalent if there exists a g in G such that
g(y2) = y1. It is an easy exercise to show that this is an equivalence relation. The set of
points, Ey = {y : g(y
) = y for some $g \in G$}, is called an equivalence class, or an orbit.
Thus, y1 and y2 are equivalent if they lie in the same orbit. Definition 3.4 says that a mixed
strategy q for Player II is invariant if it is constant on orbits, that is, if it assigns the same
probability to all pure strategies in the orbit. The power of this notion is contained in the
following theorem.
%=========================================================%
\begin{framed}
Theorem 3.4. If a finite game G = (X, Y, A) is invariant under a group G, then there
exist invariant optimal strategies for the players.
\end{framed}
Proof. It is sufficient to show that Player II has an invariant optimal strategy. Since the
game is finite, there exists a value, V , and an optimal mixed strategy for player II, q∗.
This is to say that


y∈Y
A(x, y)q∗(y) \leq V for all x ∈ X. (35)
We must show that there is an invariant strategy q˜ that satisfies this same condition. Let
N = |G| be the number of elements in the group G. Define
q˜(y) = 1
N


g∈G
q∗(g(y)) (36)
(This takes each orbit and replaces each probability by the average of the probabilities in
the orbit.) Then q˜ is invariant since for any g ∈ G,
q˜(g
(y)) = 1
N


g∈G
q∗(g(g
(y)))
= 1
N


g∈G
q∗(g(y)) = ˜q(y)
(37)
II – 27
since applying g to Y = {1, 2, \ldots,n} is just a reordering of the points of Y . Moreover, q˜
satisfies (35) since


y∈Y
A(x, y)˜q(y) = 

y∈Y
A(x, y) 1
N


g∈G
q∗(g(y))
= 1
N


g∈G


y∈Y
A(x, y)q∗(g(y))
= 1
N


g∈G


y∈Y
A(g(x), g(y))q∗(g(y))
= 1
N


g∈G


y∈Y
A(g(x), y)q∗(y)
\leq
1
N


g∈G
V = V.
(38)
In matching pennies, X = Y = {1, 2}, and A(1, 1) = A(2, 2) = 1 and A(1, 2) =
A(2, 1) = −1. The Game G = (X, Y, A) is invariant under the group G = {e, g}, where e is
the identity transformation, and g is the transformation, g(1) = 2, g(2) = 1. The (mixed)
strategy (q(1), q(2)) is invariant under G if q(1) = q(2). Since q(1) + q(2) = 1, this implies
that q(1) = q(2) = 1/2 is the only invariant strategy for Player II. It is therefore minimax.
Similarly, p(1) = p(2) = 1/2 is the only invariant, and hence minimax, strategy for Player
I.
Similarly, the game of paper-scissors-rock is invariant under the group G = {e, g, g2},
where g(paper)=scissors, g(scissors)=rock and g(rock)=paper. The unique invariant, and
hence minimax, strategy gives probability 1/3 to each of paper, scissors and rock.
Colonel Blotto Games. For more interesting games reduced by invariance, we
consider a class of tactical military games called Blotto Games, introduced by Tukey
(1949). There are many variations of these games; just google “Colonel Blotto Games”
to get a sampling. Here, we describe the discrete version treated in Williams (1954),
Karlin(1959) and Dresher (1961).
%================================================================================%
Colonel Blotto has 4 regiments with which to occupy two posts. The famous Lieutenant
Kije has 3 regiments with which to occupy the same posts. The payoff is defined as
follows. The army sending the most units to either post captures it and all the regiments
sent by the other side, scoring one point for the captured post and one for each captured
regiment. If the players send the same number of regiments to a post, both forces withdraw
and there is no payoff.
Colonel Blotto must decide how to split their forces between the two posts. There are
5 pure strategies they may employ, namely, X = {(4, 0),(3, 1),(2, 2),(1, 3),(0, 4)}, where
(n1, n2) represents the strategy of sending n1 units to post number 1, and n2 units to post
%- II – 28
number two. Lieutenant Kije has 4 pure strategies, Y = {(3, 0),(2, 1),(1, 2),(0, 3)}. The
payoff matrix is
⎛
⎜⎜⎜⎜⎝
(3, 0) (2, 1) (1, 2) (0, 3)
(4, 0) 4 2 1 0
(3, 1) 1 3 0 −1
(2, 2) −22 2 −2
(1, 3) −10 3 1
(0, 4) 0 1 2 4
⎞
⎟⎟⎟⎟⎠
(39)
Unfortunately, the 5 by 4 matrix game cannot be reduced by removing dominated
strategies. So it seems that to solve it, we must use the simplex method. However, there is
an invariance in this problem that simplifies it considerably. This involves the symmetry
between the posts. This leads to the group, G = {e, g}, where
g((3, 0)) = (0, 3) g((0, 3)) = (3, 0) g((2, 1)) = (1, 2) g((1, 2)) = (2, 1)
and the corresponding group, G = {e, g}, where
g((4, 0)) = (0, 4) g((0, 4)) = (4, 0) g((3, 1)) = (1, 3) g((1, 3)) = (3, 1)
and g((2, 2)) = (2, 2)
The orbits for Kije are {(3, 0),(0, 3)} and {(2, 1),(1, 2)}. Therefore a strategy, q, is
invariant if q((3, 0)) = q((0, 3)) and q((2, 1)) = q((1, 2)). Similarly, the orbits for Blotto
are {(4, 0),(0, 4)}, {(3, 1),(1, 3)} and {(2, 2)}. So a strategy, p, for Blotto is invariant if
p((4, 0)) = p((0, 4)) and p((3, 1)) = p((1, 3)).
We may reduce Kije’s strategy space to two elements, defined as follows:
(3, 0)∗: use (3, 0) and (0, 3) with probability 1/2 each.
(2, 1)∗: use (2, 1) and (1, 2) with probability 1/2 each.
Similarly, Blotto’s strategy space reduces to three elements:
(4, 0)∗: use (4, 0) and (0, 4) with probability 1/2 each.
(3, 1)∗: use (3, 1) and (1, 3) with probability 1/2 each.
(2, 2): use (2, 2).
With these strategy spaces, the payoff matrix becomes
⎛
⎝
(3, 0)∗ (2, 1)∗
(4, 0)∗ 2 1.5
(3, 1)∗ 0 1.5
(2, 2) −2 2
⎞
⎠ (40)
\begin{itemize}
\itemAs an example of the computations used to arrive at these payoffs, consider the upper
left entry. If Blotto uses (4,0) and (0,4) with probability 1/2 each, and if Kije uses (3,0)
%%-- II – 29
and (0,3) with probability 1/2 each, then the four corners of the matrix (39) occur with
probability 1/4 each, so the expected payoff is the average of the four numbers, 4, 0, 0, 4,
namely 2.
\item To complete the analysis, we solve the game with matrix (40). We first note that
the middle row is dominated by the top row (even though there was no domination in the
original matrix). Removal of the middle row reduces the game to a 2 by 2 matrix game
whose solution is easily found. 
\item The mixed strategy (8/9,0,1/9) is optimal for Blotto, the
mixed strategy (1/9,8/9) is optimal for Kije, and the value is V = 14/9.
\item Returning now to the original matrix (39), we find that (4/9,0,1/9,0,4/9) is optimal
for Blotto, (1/18,4/9,4/9,1/18) is optimal for Kije, and V = 14/9 is the value.
\end{itemize}
%=========================================%
\subsection{3.7 Exercises.}
1. Consider the game with matrix
\[\begin{array}{ccc}
−2 & 2 & −1\\
1& 1 1\\
3& 0& 1 \\
\end{array}.\]

\item[(a)] Note that this game has a saddle point.
\item[(b)] Show that the inverse of the matrix exists.
\item[(c)] Show that II has an optimal strategy giving positive weight to each of their columns.
\item[(d)] Why then, don’t equations (16) give an optimal strategy for II?
2. Consider the diagonal matrix game with matrix (18).
\item[(a)] Suppose one of the diagonal terms is zero. What is the value of the game?
\item[(b)] Suppose one of the diagonal terms is positive and another is negative. What is
the value of the game?
\item[(c)] Suppose all diagonal terms are negative. What is the value of the game?
3. Player II chooses a number $j \in {1, 2, 3, 4}$, and Player I tries to guess what number
II has chosen. If they guesses correctly and the number was j, they win  2j dollars from II.
Otherwise there is no payoff. Set up the matrix of this game and solve.
4. Player II chooses a number $j \in {1, 2, 3, 4}$ and I tries to guess what it is. If
he guesses correctly, they win  1 from II. If they overestimates they win  1/2 from II. If he
underestimates, there is no payoff. Set up the matrix of this game and solve.
5. Player II chooses a number $j \in {1, 2,\ldots,n}$ and I tries to guess what it is. If he
guesses correctly, they win  1. If they guesses too high, they loses 1. If they guesses too low, there
is no payoff. Set up the matrix and solve.
6. Player II chooses a number $j \in {1, 2,\ldots,n}$, $n \geq 2$, and Player I tries to guess
what it is by guessing some i ∈ {1, 2, \ldots,n}. If they guesses correctly, i.e. i = j, they win  1.
If i>j, they win  bi−j for some number b < 1. Otherwise, if i<j, they win  nothing. Set up
II – 30
the matrix and solve. Hint: If An = (aij ) denotes the game matrix, then show the inverse
matrix is A−1
n = (aij ), where aij =
 1 if i = j
−b if i = j + 1
0 otherwise
, and use Theorem 3.2.
7. The Pascal Matrix Game. The Pascal matrix of order n is the n × n matrix
Bn of elements bij , where
bij =
i − 1
j − 1

if i \geq j, and bij = 0 if i<j.
The ith row of Bn consists of the binomial coefficients in the expansion of (x + y)i
. Call
and Velleman (1993) show that the inverse of Bn is the the matrix An with entries aij ,
where aij = (−1)i+j bij . Using this, find the value and optimal strategies for the matrix
game with matrix An.
8. Solve the games with the following matrices.
\item[(a)]
⎛
⎝
1 −1 −1
021
003
⎞
⎠ \item[(b)]
⎛
⎜⎝
21 1 1
1 3/21 1
114/3 1
11 15/4
⎞
⎟⎠
\item[(c)]
⎛
⎜⎝
2002
0300
0043
1101
⎞
⎟⎠
9. Another Mendelsohn game. Two players simultaneously choose an integer
between 1 and n inclusive, where n \geq 5. If the numbers are equal there is no payoff. The
player that chooses a number one larger than that chosen by their opponent wins 2. The
player that chooses a number two or more larger than that chosen by their opponent loses
1.
\item[(a)] Set up the game matrix.
\item[(b)] It turns out that the optimal strategy satisfies pi > 0 for i = 1, \ldots, 5, and pi = 0 for all
other i. Solve for the optimal p. (It is not too difficult since you can argue that p1 = p5
and p2 = p4 by symmetry of the equations.) Check that in fact the strategy you find is
optimal.
10. Silverman Games. (See R. T. Evans (1979) and Heuer and Leopold-Wildburger
(1991).) Two players simultaneously choose positive integers. As in Mendelsohn games, a
player wants to choose an integer larger but not too much larger than the opponent, but in
Silverman games “too much larger” is determined multiplicatively rather than additively.
Solve the following example: The player whose number is larger but less than three times
as large as the opponent’s wins 1. But the player whose number is three times as large or
larger loses 2. If the numbers are the same, there is no payoff.
\item[(a)] Note this is a symmetric game, and show that dominance reduces the game to a 3 by
II – 31
3 matrix.
\item[(b)] Solve.
11. Solve the following games.
\item[(a)]
⎛
⎝
0 1 −2
−103
2 −3 0
⎞
⎠ \item[(b)]
⎛
⎝
0 1 −2
−201
1 −2 0
⎞
⎠
\item[(c)]
⎛
⎜⎜⎜⎝
1 4 −1 5
4 −151
−1514
514 −1
2222
⎞
⎟⎟⎟⎠
12. Run the original Blotto matrix (39) through the Matrix Game Solver, on the
web at: http://www.math.ucla.edu/˜tom/gamesolve.html, and note that it gives different
optimal strategies than those found in the text. What does this mean? Show that (3, 1)∗ is
strictly dominated in (40). This means that no optimal strategy can give weight to (3, 1)∗.
Is this true for the solution found?
13. \item[(a)] Suppose Blotto has 2 units and Kije just 1 unit, with 2 posts to capture.
Solve.
\item[(b)] Suppose Blotto has 3 units and Kije 2 units, with 2 posts to capture. Solve.
14. \item[(a)] Suppose there are 3 posts to capture. Blotto has 4 units and Kije has 3. Solve.
(Reduction by invariance leads to a 4 by 3 matrix, reducible further by domination to 2
by 2.)
\item[(b)] Suppose there are 4 posts to capture. Blotto has 4 units and Kije has 3. Solve.
(A 5 by 3 reduced matrix, reducible by domination to 4 by 3. But you may as well use
the Matrix Game Solver to solve it.)
%===================================================================%
\subsection{15. Battleship.}
The game of Battleship, sometimes called Salvo, is played on two
square boards, usually 10 by 10. Each player hides a fleet of ships on their own board and
tries to sink the opponent’s ships before the opponent sinks his. (For one set of rules, see
http://www.kielack.de/games/destroya.htm, and while you are there, have a game.)
For simplicity, consider a 3 by 3 board and suppose that Player I hides a destroyer
(length 2 squares) horizontally or vertically on this board. Then Player II shoots by calling
out squares of the board, one at a time. After each shot, Player I says whether the shot
was a hit or a miss. Player II continues until both squares of the destroyer have been hit.
The payoff to Player I is the number of shots that Player II has made. Let us label the
squares from 1 to 9 as follows.
1 2 3
4 5 6
7 8 9
II – 32
The problem is invariant under rotations and reflections of the board. In fact, of
the 12 possible positions for the destroyer, there are only two distinct invariant choices
available to Player I: the strategy, [1, 2]∗, that chooses one of [1,2], [2,3], [3,6], [6,9], [8,9],
[7,8], [4,7], and [1,4], at random with probability 1/8 each, and the strategy, [2, 5]∗, that
chooses one of [2,5], [5,6], [5,8], and [4,5], at random with probability 1/4 each. This means
that invariance reduces the game to a 2 by n game where n is the number of invariant
strategies of Player II. Domination may reduce it somewhat further. Solve the game.
16. Dresher’s Guessing Game. Player I secretly writes down one of the numbers
1, 2, \ldots,n. Player II must repeatedly guess what I’s number is until they guesses correctly,
losing 1 for each guess. After each guess, Player I must say whether the guess is correct,
too high, or too low. Solve this game for n = 3. (This game was investigated by Dresher
(1961) and solved for n \leq 11 by Johnson (1964). A related problem is treated in Gal
(1974).)
17. Thievery. Player I wants to steal one of m \geq 2 items from Player II. Player II
can only guard one item at a time. Item i is worth ui > 0, for i = 1, \ldots,m. This leads to
a matrix game with m × m matrix,
A =
⎛
⎜⎜⎜⎜⎝
0 u1 u1 ... u1
u2 0 u2 ... u2
u3 u3 0 ... u3
.
.
. .
.
. .
.
. ... .
.
.
um um um ... 0
⎞
⎟⎟⎟⎟⎠
Solve!
Hint: It might be expected that for some k \leq m Player I will give all their probability
to stealing one of the k most expensive items. Order the items from most expensive to
least expensive, $u1 \geq u2 \geq ... \geq um > 0$, and use the principle of indifference on the upper
left k × k submatrix of A for some k.
18. Player II chooses a number $j \in {1, 2,\ldots,n}$, n \geq 2, and Player I tries to guess
what it is by guessing some i ∈ {1, 2, \ldots,n}. If they guesses correctly, i.e. i = j, they win  2.
If they misses by exactly 1, i.e. |i − j| = 1, then they loses 1. Otherwise there is no payoff.
Solve. Hint: Let An denote the n by n payoff matrix, and show that A−1 n = Bn = (bij ),
where bij = i(n + 1 − j)/(n + 1) for i \leq j, and bij = bji for i>j.
%================================================================================%
\subsection{19. The Number Hides Game.} 
The Number Hides Game, introduced by Ruckle
(1983) and solved by Baston, Bostock and Ferguson (1989), may be described as follows.
From the set S = {1, 2, \ldots,k}, Player I chooses an interval of m1 consecutive integers
and Player II chooses an interval of m2 consecutive integers. The payoff to Player I is
the number of integers in the intersection of the two intervals. When k = n + 1 and
m1 = m2 = 2, this game is equivalent to the game with n × n matrix An = (aij ), where
aij =
 2 if i = j
1 if |i − j| = 1
0 otherwise.
II – 33
[In this form, the game is also a special case of the Helicopter versus Submarine
Game, solved in the book of Garnaev (2000), in which the payoff for |i − j| = 1 is allowed
to be an arbitrary number a, 0 \leq a \leq 1.] Since A−1 n is just Bn of the previous exercise
with bij replaced by (−1)i+j bij , the solution can be derived as in that exercise. Instead,
just show the following.
\begin{itemize}
\item[\item[(a)]] For n odd, the value is Vn = 4/(n + 1). There is an optimal equalizing strategy
(the same for both players) that is proportional to (1, 0, 1, 0, \ldots, 0, 1).
\item[\item[(b)]] For n even, the value is 4(n+1)/(n(n+2)). There is an optimal equalizing strategy
(the same for both players) that is proportional to $(k, 1, k − 1, 2, k − 2, 3, \ldots, 2, k − 1, 1, k)$,
where k = n/2.
\end{itemize}

