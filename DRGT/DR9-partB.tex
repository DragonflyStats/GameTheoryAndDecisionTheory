
\documentclass[]{report}
\voffset=-1.5cm
\oddsidemargin=0.0cm
\textwidth = 480pt


\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{multicol}
%\usepackage[paperwidth=21cm, paperheight=29.8cm]{geometry}
%\usepackage[angle=0,scale=1,color=black,hshift=-0.4cm,vshift=15cm]{background}
%\usepackage{multirow}
\usepackage{enumerate}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{color}
\usepackage{multirow}
\usepackage{eurosym}
\usepackage{framed}

%\input def.tex
%\input dsdef.tex
%\input rgb.tex

%\newcommand \la{\lambda}
%\newcommand \al{a}
%\newcommand \be{b}
\newcommand \x{\overline{x}}
\newcommand \y{\overline{y}}

\begin{document}
\section{”Stern” Strategies in Prisoner’s Dilemma Type Games}
The stern strategy S cooperates until the other player defects and
then always defects.
After defecting against a stern player, it is clear that the defector
should carry on defecting (since the stern player will always defect
from then onwards and defection is the best response to this).
In order to check whether S is a Nash equilibrium, we only have to
check that R1(S, S) ≥ R1(D, S).
24 / 50
”Stern” Strategies in Prisoner’s Dilemma Type Games
It follows that if tit-for-tat is a Nash equilibrium, then ”stern” is
also a Nash equilibrium.
Note that in a population comprised purely of stern and tit-for-tat
players, everyone will always cooperate.
One advantage of tit-for-tat occurs when with a small probability
players make a mistake when choosing an action or perceiving the
action taken by the other player.
If players use ”stern”, then after a defection cooperation breaks
down. Using tit-for-tat (or a similar reactive but forgiving
strategy), cooperation may well be re-established.
25 / 50

\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
The repeated version of the Cournot game takes into account that
firms will face a sequence of production decisions and take the
previous behaviour of competitors into account.
What strategies in the repeated symmetric Cournot game would
correspond to C, D and S in the repeated prisoner’s dilemma
game?
The corresponding strategy to C would be the strategy which
when followed by both firms would maximise the sum of the profits
(these would be split evenly between the firms).
The corresponding strategy to D would be the strategy both firms
follow at the unique Nash equilibrium of the Cournot game.
26 / 50

\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
The corresponding strategy to S would be the strategy: follow the
profit maximisation strategy C as long as the other firm does the
same, always play the strategy corresponding to the standard
Cournot game after the other firm has deviated from the profit
maximisation strategy.
For simplicity, we do not consider the analogous strategy to
tit-for-tat.
Such defection only pays if the short-term reward from the initial
defection outweighs the later loss from the lack of collusion. The
only deviation from tit-for-tat we need to consider is the best
response to the collusive strategy followed by repeating the
Cournot equilibrium strategy.
27 / 50

\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
We assume that the payoff obtained in round i is discounted by a
factor of ω
i−1
compared to the payoff obtained in round 1 (as in
the second interpretation of the iterated prisoner’s dilemma game).
The method of finding the values of ω for which collusion is a
Nash equilibrium is similar to the method used for the prisoner’s
dilemma.
1. We derive the symmetric action pair (i.e. both firms
choose the same production level) that maximises
the sum of profits. The corresponding action pair is
(C, C).
2. We derive the Cournot equilibrium of the single-shot
game and the associated profits. The corresponding
action pair is (D, D),
%=======================================%
%%- 28 / 50
\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
3. We derive the best response to C and the payoffs
obtained in this case. The corresponding action pair
is (C, D).
4. We compare the discounted reward of a defector
playing against a firm using S with the discounted
reward of a firm playing S against another playing S.
5. Without loss of generality, we may assume that
defection occurs in round 1.
%%- 29 / 50
\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
Consider the repeated Cournot game where the production of firm
i in a period is xi
.
The price in a period is given by p = 3 −
x1+x2
1000 .
The costs incurred by firm i in a period are given by
ci(x) = 100 + xi
.
30 / 50
\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
Note that this is the problem considered in Section 3.6.
Player 1’s best response to x2 is 1000 −
x2
2
, when x2 ≤ 2000.
The Cournot equilibrium for this game is for both firm to produce
2000
3
units per period.
The profits obtained by both players at the Cournot equilibrium are
approximately 344.
31 / 50
\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
We need to derive the total production xtot = x1 + x2 which
maximises the total reward of the two firms.
The total costs incurred by the firms are
c1(x1) + c2(x2) = 200 + x1 + x2 = 200 + xtot
The total revenue is pxtot = (3 −
xtot
1000 )xtot = 3xtot −
x
2
tot
1000 .
It follows that the total profit is
Rtot = pxtot − c1(x1) − c2(x2) = 2xtot −
x
2
tot
1000 − 200.
32 / 50
\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
Differentiating with respect to xtot, we obtain
∂Rtot
∂xtot
= 2 −
xtot
500
.
It follows that the optimal joint production is 1000, i.e. each firm
produces 500 units per period.
The total profit is 800, i.e. each firm makes a profit of 400 units at
this ”collusive solution”.
33 / 50
Implicit Collusion in the Repeated Version of the
Symmetric Cournot Game
We now derive the optimal response to this collusive level of
production.
The analysis leading to the Cournot equilibrium shows that the
optimal response of a firm when the other produces 500 units is to
produce 1000 −
500
2 = 750 units.
We now calculate the profit obtained by the ”defector” in this case.
The price when the strategy pair is (500,750) is given by
p = 3 −
1250
1000 = 1.75.
34 / 50
Implicit Collusion in the Repeated Version of the
Symmetric Cournot Game
The ”defector” obtains
R2(500, 750) = 750 × 1.75 − 100 − 750 = 462.5.
We can now find the values of ω for which collusion is a Nash
equilibrium in the repeated game.
35 / 50
Implicit Collusion in the Repeated Version of the
Symmetric Cournot Game
The stern strategy, S, is to produce 500 units in a period as long
as the other firm produces 500 units in a period and then always
produce 2000
3
units in a period.
A defector, denoted D, produces 750 units in the first period and
then produces 2000
3
units in a period.
Two firms playing S obtain 400 units per period. Their discounted
reward is
R1(S, S) = 400 + 400ω + 400ω
2 + . . . =
400
1 − ω
36 / 50
\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
The payoff of a defector against a stern player is 462.5 in round 1
and 344 in subsequent rounds. Hence,
R1(D, S) = 462.5 + 344ω + 344ω
2 + . . . = 462.5 +
344ω
1 − ω
.
Tit-for-tat is a Nash equilibrium in the repeated game if
400
1 − ω
≥ 462.5 +
344ω
1 − ω
⇒ ω ≥ 0.5274.
37 / 50
\subsection{Implicit Collusion in the Repeated Version of the Symmetric Cournot Game}
The concept of collusion can be applied to asymmetric games.
However, it is not so clear how to split the gains from collusion.
One possibility is that both firms split the gains from collusion
equally between each other.
Another possibility is that the ratio between the profits of the firms
at a collusive solution is equal to the ratio between the profits of
the firms at the equilibrium of the corresponding one-shot Cournot
(or Stackelberg) game.
These two possibilities are equivalent in the case of symmetric
games.
38 / 50
%======================================%
\subsection{Equilibria in infinitely Repeated Games Without Discounting}
In the Hawk-Dove game playing the pair of actions (D, H) and
(H, D) in alternate rounds is a Nash equilibrium in any n-repeated
Hawk-Dove game, i.e. each pure Nash equilibrium pair is played
half the time.
Compare this solution to the egalitarian correlated equilibrium
”toss a coin” if the result is heads play (H, D) and (D, H).
If the game is repeated infinitely often, any solution where (H, D)
is played a proportion p of the time and (D, H) is played a
proportion 1 − p of the time is a Nash equilibrium.
Hence, any expected payoff vector at a correlated equilibrium
which is a randomisation over the set of Nash equilibria can be
achieved at a Nash equilibrium in an infinitely repeated game (in
the sense of mean payoff per round).
39 / 50
%======================================%
\subsection{Set of Possible Payoff Rates in Infinitely Repeated Games}
Over an infinite horizon the mean (undiscounted) reward of the
players per period is given by a weighted mean of all the payoff
vectors over all the possible action pairs. The weights are the
frequencies with which each action pair is played.
Hence, the set of attainable mean rewards is the same as the set of
attainable expected rewards using a correlated equilibrium.
40 / 50
%======================================%
\subsection{The Folk Theorem}
The Folk Theorem: In an infinitely repeated game, for any mean
payoff vector (per round) in which both players obtain at least
their corresponding minimax reward there is a Nash equilibrium.
There is no equilibrium at which at least one player obtains less
than their minimax reward.
Such a Nash equilibrium is defined by a pair of strategies that give
the required mean payoff vector plus the threat that if the other
player ”defects” from this strategy pair, then a player will play so
as to minimise the payoff of the defector.
41 / 50
%======================================%
\subsection{The Folk Theorem}
It follows that in such an infinitely repeated game a Nash
equilibrium which satisfies any sensible optimality condition must
be Pareto optimal.
This follows since if a solution is not Pareto optimal, we can always
find a Nash equilibrium at which one player obtains a greater mean
reward without reducing the mean reward of the other player.
42 / 50
Example
Consider the infinitely repeated version of the chicken game
A B
A (6,6) (2,8)
B (8,2) (0,0)
43 / 50
Example
First we derive the minimax payoffs in the one-shot game (note
that the game is symmetric).
Suppose Player 1 takes action A with probability p and Player 2
takes action A with probability q.
R1(M1, M2) = 6pq + 2p(1 − q) + 8(1 − p)q = 2p + 8q − 4pq.
44 / 50
%======================================%
\subsection{Example}
We wish to find the strategy of Player 2 which minimises Player 1’s
expected reward. Hence, we calculate the derivative of Player 1’s
reward with respect to q (the decision of Player 2).
∂R1(M1, M2)
∂q
= 8 − 4p.
This is positive for all p. Hence, to minimise Player 1’s payoff,
Player 2 should choose q to be as small as possible.
It follows that Player 2 minimises Player 1’s reward by always
taking action B.
45 / 50
Example
If Player 2 plays B, then Player 1 should play A.
It follows that Player 1’s minimax reward is 2. By symmetry, this is
the minimax payoff of Player 2.
Hence, at any Nash equilibrium of the infinitely repeated game,
both players must obtain a payoff of at least 2.
46 / 50
The Set of Attainable Mean Payoff Vectors
R2
R1
•
•
•
•
✘✘✘✘✘✘✘✘✘✘✘✘✘✘✘✘
✄
✄
✄
✄
✄
✄
✄
✄
✄
✄
✄
✄
✄
✄
✄
✄
❆
❆
❆
❆
❆
❆
❆
❆
❍❍❍❍❍❍❍❍
0
(8,2)
(2,8)
(6,6)
S
47 / 50
Example
Suppose we wish to find the Nash equilibrium which a) maximises
the mean payoff of Player 1, b) maximises the sum of the mean
payoffs.
a) The mean payoff vector at such a solution is the Pareto optimal
mean payoff vector which gives Player 2 at least 2 and maximises
the mean payoff of Player 1.
This is the mean payoff vector (8, 2). The players have to play the
action pair (B, A) in each round at such an equilibrium.
At such an equilibrium the threat, that a player will play B if the
other deviates from this action pair, is essentially meaningless.
Player 1 cannot gain by deviating and Player 2 deviating would
simply lead to Player 1 playing B and so Player 1 should then play
A (i.e. they return to the same action pair).
48 / 50
Example
b) The mean payoff vector at such a solution is the Pareto optimal
mean payoff vector which gives the greatest sum of mean payoffs
while ensuring both of the players at least 2.
Since the set of Pareto optimal solutions is piecewise linear (it is
made up of the lines between (2,8) and (6,6) and between (6,6)
and (8,2), the maximum sum must come at one of the endpoints
of one of these line segments.
The appropriate mean payoff vector is thus (6,6). At such an
equilibrium, the players should always play A. If either deviates
from this action, then the other should always play B.
49 / 50
Example
It should be noted that this solution cannot be attained using a
correlated equilibrium.
It follows that the ability to react to the strategy of other players
in a repeated game is a stronger force than communication
without the power of making a contract (i.e. the conditions
required for attaining a correlated equilibrium), in the sense that
the set of mean payoffs possible at an equilibrium of a repeated
game contains the set of expected payoffs using a correlated
equilibrium in a one-shot game.
50 / 50
\end{document}