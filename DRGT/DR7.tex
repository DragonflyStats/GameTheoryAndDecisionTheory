
\documentclass[]{report}
\voffset=-1.5cm
\oddsidemargin=0.0cm
\textwidth = 480pt


\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{multicol}
%\usepackage[paperwidth=21cm, paperheight=29.8cm]{geometry}
%\usepackage[angle=0,scale=1,color=black,hshift=-0.4cm,vshift=15cm]{background}
%\usepackage{multirow}
\usepackage{enumerate}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{color}
\usepackage{multirow}
\usepackage{eurosym}
\usepackage{framed}

%\input def.tex
%\input dsdef.tex
%\input rgb.tex

%\newcommand \la{\lambda}
%\newcommand \al{a}
%\newcommand \be{b}
\newcommand \x{\overline{x}}
\newcommand \y{\overline{y}}

\begin{document}
	
\section{3.7 Evolutionary Game Theory}
The Hawk-Dove game is used in biology to explain why aggression
is present within populations, but is not always observed.
Consider the symmetric Hawk-Dove game. The intuition is that
two indistinguishable individuals must decide whether to share a
resource or demand the resource for themselves.
If only one individual demands the resource, then he/she obtains
that resource (of value v).
If both demand the resource, they fight. Each wins with probability
0.5 (thus obtaining the resource). The loser pays a cost of c (due
to injuries incurred). It is assumed that c > v.
1 / 46
General Form of the Symmetric Hawk-Dove Game
The general form of the symmetric Hawk-Dove game is
H D
H (0.5[v âˆ’ c], 0.5[v âˆ’ c]) (v, 0)
D (0, v) 0.5(v, v)
2 / 46
Evolutionarily Stable Strategies in Symmetric 2-Player
Matrix Games (ESSs)
In a symmetric 2-player game, we may define the payoff to a player
using strategy Ï€1 against a player using strategy Ï€2 to be
R(Ï€1, Ï€2).
It is assumed that each player plays a sequence of games, with each
opponent being chosen at random from the population as a whole.
Each individual reproduces at a rate proportional to the average
reward gained in these games (or proportional to some increasing
function of this average reward).
It is assumed that the population size is very large (essentially
infinite).
3 / 46
Evolutionarily Stable Strategies in Symmetric 2-Player
Matrix Games (ESSs)
An ESS, Ï€
âˆ— of a symmetric game is a strategy that will be selected
for when adopted by virtually the whole population. In
mathematical terms, Ï€
âˆ—
is an ESS if
Either 1) R(Ï€
âˆ—
, Ï€âˆ—
) > R(Ï€, Ï€âˆ—
), âˆ€Ï€ 6= Ï€
âˆ—
or 2) R(Ï€
âˆ—
, Ï€âˆ—
) â‰¥ R(Ï€, Ï€âˆ—
), âˆ€Ï€ and if R(Ï€, Ï€âˆ—
) = R(Ï€
âˆ—
, Ï€âˆ—
) for
some Ï€ 6= Ï€
âˆ—
, then R(Ï€, Ï€) < R(Ï€
âˆ—
, Ï€).
4 / 46
\subsection{Weak and Strong ESSs}
Any ESS which satisfies Condition 1 is called a strong ESS.
A strong, symmetric Nash equilibrium of a symmetric game â‡”
Strong ESS of symmetric game.
Any ESS which does not satisfy Condition 1, but satisfies
Condition 2 is called a weak ESS.
5 / 46
Evolutionarily Stable Strategies in Symmetric 2-Player
Matrix Games (ESSs)
The first condition states that if a player knows that an opponent
will play Ï€
âˆ—
, then he/she does strictly better by playing Ï€
âˆ—
than by
playing any other strategy.
i.e. Any individual playing a different strategy from Ï€
âˆ— would be
selected against.
The second condition states that if there exists an individual
mutant (individual not using Ï€
âˆ—
) who is not selected against, then
when the frequency of such mutants is close to zero (but positive),
then such mutants are selected against.
6 / 46
Evolutionarily Stable Strategies in Symmetric 2-Player
Matrix Games (ESSs)
To see this is the case, suppose that Condition 2 is satisfied and a
proportion 1 âˆ’  play Ï€
âˆ—
and a proportion  play Ï€, where  is small.
Since each opponent is chosen from the population as a whole, the
average reward obtained by Ï€
âˆ— players is
R(Ï€
âˆ—
,(1 âˆ’ )Ï€
âˆ— + Ï€) = (1 âˆ’ )R(Ï€
âˆ—
, Ï€âˆ—
) + R(Ï€
âˆ—
, Ï€).
The average reward obtained by Ï€
âˆ— players is
R(Ï€,(1âˆ’)Ï€
âˆ—+Ï€) = (1âˆ’)R(Ï€, Ï€âˆ—
)+R(Ï€, Ï€) < R(Ï€
âˆ—
,(1âˆ’)Ï€
âˆ—+Ï€).
If Condition 1 is satisfied, then there is a value 0 > 0 such that
this inequality is satisfied for all  < 0.
7 / 46
Evolutionarily Stable Strategies in Symmetric 2-Player
Matrix Games (ESSs)
Due to the linearity of the payoff function when a player faces an
opponent using a mixed strategy, when checking the stability
conditions we may assume that any mutant uses a pure strategy.
It should be noted that at an ESS of a symmetric game, each
individual should use the same strategy.
i.e. an ESS of a symmetric game is given by a single strategy,
while a Nash equilibrium is given by a pair of strategies.
Hence, the non-symmetric Nash equilibria [(H, D) and (D, H)] of
the Hawk-Dove game do not correspond to an evolutionarily stable
strategy of the Hawk-Dove game.
8 / 46
Relation Between ESSs and Nash Equilibria in Symmetric
Games
An ESS of a symmetric game must correspond to a symmetric
Nash equilibrium of that game (an ESS of a symmetric game is a
Nash equilibrium in which both players play the same strategy).
Hence, the concept of an ESS is a refinement of the concept of a
Nash equilibrium.
Any non-trivial 2Ã—2 symmetric matrix game has an ESS.
Non-trivial - the payoff is essentially dependent on the pair of
actions taken.
9 / 46
ESSs of Symmetric Matrix Games
To derive the ESSs of a symmetric matrix game, we
1. Find all the symmetric pure Nash equilibria (i.e. Nash
equilibria where both players always use the same
action). These are always ESSs (called pure ESSs).
2. Find the mixed equilibria and check whether they
satisfy the equilibrium condition (such ESSs are
called mixed ESSs).
10 / 46
ESSs of the Hawk-Dove Game
First we look for a pure ESS of the game.
(H, H) is not a pure ESS, since both players obtain a negative
expected payoff and by changing unilaterally to D, either one can
increase their payoff to 0.
(D, D) is not a pure ESS, since both players obtain v/2. By
changing unilaterally to H, a player can gain an expected reward of
v.
There is no pure ESS. We thus look for a mixed ESS.
11 / 46
ESSs of the Hawk-Dove Game
We first look for a mixed Nash equilibrium using the
Bishop-Cannings theorem.
Note any mixed equilibrium of a symmetric 2Ã—2 game is
symmetric.
Suppose the mixed Nash equilibrium is
[pH + (1 âˆ’ p)D, pH + (1 âˆ’ p)D]. When an opponent plays this
strategy a player is indifferent between H and D. Hence,
R(H, pH + (1 âˆ’ p)D)=R(D, pH + (1 âˆ’ p)D)
0.5p(v âˆ’ c) + (1 âˆ’ p)v=0.5(1 âˆ’ p)v â‡’ p =
v
c
12 / 46
ESSs of the Hawk-Dove Game
Hence, the probability of playing H (level of aggression) is
increasing in the value of the resource and decreasing in the costs
incurred in losing a fight.
Note that any mixed ESS is by definition a weak ESS.
This is due to the fact that when all the population use a strategy
corresponding to a mixed Nash equilibrium, an individual using an
action in the support of this equilibrium (or mixture thereof) will
obtain the same expected payoff as a member of the general
population.
13 / 46
ESSs of the Hawk-Dove Game
We now check that Condition 2 for an ESS is satisfied.
This condition states that the ESS strategy must do better against
any pure strategy than the pure strategy does against itself.
Firstly, we check whether an individual using the ESS does better
against a hawk than a hawk does against another hawk, i.e.
R(pH + (1 âˆ’ p)D, H) > R(H, H). We have
R(pH + (1 âˆ’ p)D, H) = 0.5p(v âˆ’ c) > R(H, H) = 0.5(v âˆ’ c),
since p < 1 and v âˆ’ c < 0.
14 / 46
ESSs of the Hawk-Dove Game
Secondly, we check whether an individual using the ESS does
better against a dove than a dove does against another dove, i.e.
R(pH + (1 âˆ’ p)D, D) > R(D, D). We have
R(pH + (1 âˆ’ p)D, D) = pv + (1 âˆ’ p)v/2 > R(D, D) = v/2.
Hence, pH + (1 âˆ’ p)D is an ESS.
15 / 46
Interpretation of Mixed ESSs
One may ask the following question: does the existence of a mixed
ESS in which all individuals play H with probability p and play D
with probability 1 âˆ’ p mean that there is an equilibrium in which a
proportion p of individuals always play H and a proportion 1 âˆ’ p
always play D?
Such an equilibrium is called a stable polymorphism (different
individuals use different strategies).
In the types of game we consider, the answer to the above
question is â€Yesâ€. Hence, we can think of a population following a
mixed strategy as being equivalent to a population in which the
proportion of individuals using each pure action is equal to the
probability of using that action under the mixed strategy.
16 / 46
Coordination and Anti-Coordination Games
The Hawk-Dove game is an example of an anti-coordination game.
An anti-coordination game is a symmetric 2Ã—2 game in which
there are 2 pure equilibria where the players take differing actions.
In such games the mixed equilibrium is the unique ESS.
In co-ordination games there are 2 pure, symmetric Nash equilibria
(i.e. players take the same action at a Nash equilibrium).
17 / 46
ESSs in a Co-ordination Game
Suppose two individuals play the following game.
A B
A (5, 5) (0, 0)
B (0, 0) (1, 1)
18 / 46
ESSs in a Co-ordination Game
It is simple to check that (A, A) and (B, B) are strong Nash
equilibria.
Hence, both A and B are ESSs.
There is a mixed Nash equilibrium [pA + (1 âˆ’ p)B, pA + (1 âˆ’ p)B],
where
R(A, pA + (1 âˆ’ p)B)=R(B, pA + (1 âˆ’ p)B)
5p = (1 âˆ’ p) â‡’ p =
1
6
.
19 / 46
ESSs in a Co-ordination Game
We now check whether 1
6
A +
5
6
B satisfies Condition 2 for an ESS.
We first check whether this mixed strategy does better against A
than A does against itself. We have
R(
1
6
A + (1 âˆ’ p)B, A) = 5
6
< R(A, A) = 5.
Hence, 1
6
A +
5
6
B is not an ESS. A group of mutants playing A
would obtain a higher expected payoff (i.e. invade such a
population).
20 / 46
Replicator Dynamics
When there are multiple ESSs, it is natural to ask which one would
be favoured by natural selection.
It is clear that this depends on the initial population. If in the
co-ordination game most of the population are playing A, then the
population would evolve so that eventually all the population plays
A.
Similarly, if nearly all of the population are playing B, then the
population would evolve so that eventually all the population plays
B.
Replicator dynamics are used to simulate the evolution of such a
population.
21 / 46
3.8 Replicator Dynamics in Symmetric Games
Suppose players choose one of m actions. The payoff of a player
when he/she plays Ai and the opponent plays Aj
is R(Ai
, Aj),
where R(Ai
, Aj) â‰¥ 0.
It is assumed that individuals use pure strategies, i.e. they always
use the same action.
Let pi,n be the proportion of individuals using action i in
generation n.
22 / 46
Replicator Dynamics in Symmetric Games
Denote the average reward of an individual using action i in
generation n by Ri,n. We have
Ri,n = R(Ai
, p1,nA1 + p2,nA2 + . . . + pm,nAm).
Denote the average reward in the population as a whole in
generation n as Rn. We have
Rn =
Xm
i=1
pi,nRi,n.
23 / 46
Replicator Dynamics in Symmetric Games
Individuals using action i are assumed to reproduce in proportion
to the average reward of these individuals. It follows that the
proportion of individuals using action i in generation i + 1 is given
by
pi,n+1 =
pi,nRi,n
Rn
Varying i from 1 to m âˆ’ 1, we obtain the replicator dynamic
equations.
Note that pm,n = 1 âˆ’
Pmâˆ’1
i=1 pi,n.
24 / 46
Fixed Points of the Replicator Dynamic Equations
A fixed point (p1, p2, . . . , pm) of the replicator dynamic equations
satisfies
pi =
piRi
R
, âˆ€i = 1, 2, . . . , m.
where Ri and R denote the average reward of individuals taking
action i and of the population, respectively.
25 / 46
Fixed Points of the Replicator Dynamic Equations
It should be noted that all actions that occur with positive
probability have to obtain the same reward at a fixed point.
pi = 1, for some i such that 1 â‰¤ i â‰¤ m and pj = 0, âˆ€j 6= i always
defines a fixed point of the replicator dynamic equations.
A fixed point of the replicator dynamics corresponds to an ESS if
the fixed point is an attractor.
A fixed point of a dynamic process is an attractor if in some
neighbourhood of the fixed point, evolution of the system leads to
the process getting ever closer to that fixed point.
26 / 46
Example 3.8.1
Consider the co-ordination game given above.
Since there are only 2 possible actions, we need only to consider
the evolution of the proportion of individuals using A.
Let pn be the proportion of individuals using A in generation n (the
remaining individuals use B). The proportion of individuals using A
at the start of the process is p0.
27 / 46
Example 3.8.1
The average reward of A players in generation n is given by
RA,n = R(A, pnA + (1 âˆ’ pn)B) = 5pn.
The average reward of B players in generation n is given by
RB,n = R(B, pnA + (1 âˆ’ pn)B) = 1 âˆ’ pn.
28 / 46
Example 3.8.1
The average reward of the population as a whole is given by
Rn = pnRA,n + (1 âˆ’ pn)RB,n = 5p
2
n + (1 âˆ’ pn)
2 = 1 âˆ’ 2pn + 6p
2
n
.
Hence, the equation governing the replicator dynamics is
pn+1 =
pnRA,n
Rn
=
5p
2
n
1 âˆ’ 2pn + 6p
2
n
.
29 / 46
Example 3.8.1
A fixed point of these dynamics satisfies pn+1 = pn = p. We have
p =
5p
2
1 âˆ’ 2p + 6p
2 â‡’ p(1 âˆ’ 2p + 6p
2
) = 5p
2
.
p = 0 is clearly a root of this equation. Otherwise, dividing by p,
we obtain
(1 âˆ’ 2p + 6p
2
) = 5p â‡’ 1 âˆ’ 7p + 6p
2 = 0 â‡’ p = 1 or p =
1
6
.
Hence, there are 3 fixed points of the replicator dynamics 0, 1
6
and
1.
30 / 46
Example 3.8.1
Note that 0 and 1 will always be fixed points of the replicator
dynamics in 2Ã—2 games.
This is due to the fact that the replicator dynamics assume that
there is no mutation. Hence, if one of the actions is not played,
then there is no way of introducing it into the population.
We now check which of these fixed points are attractors.
31 / 46
Example 3.8.1
To check whether p = 0 is an attractor (this corresponds to the
strategy B), we assume that pn is close to 0 and see whether pn+1
is closer to 0, i.e. let pn = Î´ where Î´ is small (Î´ > 0).
We have
pn+1 âˆ’ 0 = pn+1 =
5Î´
2
1 âˆ’ 2Î´ + 6Î´
2
= Î´
5Î´
1 âˆ’ 2Î´ + 6Î´
2
.
For small Î´, pn+1 will be of the order 5Î´ times pn, i.e. less than pn.
Hence, p = 0 is an attractor.
32 / 46
Example 3.8.1
To check whether p = 1 is an attractor (this corresponds to the
strategy B), we assume that pn is close to 1, i.e. pn = 1 âˆ’ Î´,
where Î´ is small and positive.
We then look at the distance between 1 and pn+1 (normally as a
multiple of Î´). Setting pn = 1 âˆ’ Î´.
pn+1 =
5(1 âˆ’ Î´)
2
1 âˆ’ 2(1 âˆ’ Î´) + 6(1 âˆ’ Î´)
2
33 / 46
Example 3.8.1
Hence,
1 âˆ’ pn+1 = 1 âˆ’
5(1 âˆ’ Î´)
2
1 âˆ’ 2(1 âˆ’ Î´) + 6(1 âˆ’ Î´)
2
= Î´
% 
Î´
5 âˆ’ 10Î´ + 6Î´
2
% 
.
It follows that when pn is Î´ away from 1, then pn+1 will be of order
Î´
5
times further away, i.e. closer to 1.
Hence, p = 1 is an attractor.
34 / 46
Example 3.8.1
Finally, we check whether p =
1
6
is an attractor. Let pn+1 =
1
6 + Î´
and look at the distance between pn+1 and 1
6
as a multiple of Î´.
We have
pn+1 âˆ’
1
6
=
5(1/6 + Î´)
2
1 âˆ’ 2(1/6 + Î´) + 6(1/6 + Î´)
2
âˆ’
1
6
This gives
pn+1 âˆ’
1
6
= Î´
5/3 + 4Î´
5/6 + 6Î´
2
35 / 46
Example 3.8.1
It follows that the difference between pn+1 and 1
6
is of order 2Î´,
i.e. twice as far away from 1
6
.
It follows that p =
1
6
is not an attractor.
Hence, the only ESSs in this game are p = 0 (corresponding to B)
and p = 1 (corresponding to A).
36 / 46
Relation Between the Evolution of the Population and the
Risk Factor
It should be noted that if p0 >
1
6
, then the population will evolve
to everyone using A.
If p0 <
1
6
, then the population will evolve to everyone using B.
It should be noted that 1
6
is the risk factor associated with the ESS
strategy A. When the probability of an opponent playing A is
greater than 1
6
, then a player should play A.
37 / 46
3.9 Asymmetric Evolutionary Games
In general, a Hawk-Dove game will not be symmetric, e.g.
1. One individual may be bigger (stronger) than the
other and hence more likely to win a fight. For
simplicity assume that one player is always bigger and
wins a fight with probability p, where p >
1
2
.
2. Two individuals will not find a resource at the same
time, hence one can be treated as â€an ownerâ€ and
the other as â€an intruderâ€.
In such cases the strategy of an individual should take into account
the role of a player.
38 / 46
Asymmetric Evolutionary Games
Suppose that in the Hawk-Dove game one player is â€an ownerâ€
and the other player is â€an intruderâ€.
Strictly speaking, in such a game since each player can play either
role, the strategy of an individual should be given by a rule
defining how an individual behaves when she is an intruder and a
rule defining how she behaves when she is an owner.
However, assuming that it is clear which role is being played by
each individual, in order to define ESSs for such a game, we only
need to consider the game in which Player 1 is the owner and
Player 2 is the intruder.
39 / 46
Asymmetric Evolutionary Games
The payoff matrix is given by
H D
H (0.5[v âˆ’ c], 0.5[v âˆ’ c]) (v, 0)
D (0, v) 0.5(v, v)
40 / 46
Asymmetric Evolutionary Games
In this case an ESS profile (Ï€
âˆ—
1
, Ï€âˆ—
2
) satisfies the condition that if
the vast majority of the population play Ï€
âˆ—
1 when in Role 1 and Ï€
âˆ—
2
when in Role 2, then an individual who plays a different strategy in
either role will be selected against.
It follows that (Ï€
âˆ—
1
, Ï€âˆ—
2
) is an ESS profile if
R1(Ï€
âˆ—
1
, Ï€âˆ—
2
)>R1(Ï€1, Ï€âˆ—
2
), âˆ€Ï€1 6= Ï€
âˆ—
1
R2(Ï€
âˆ—
1
, Ï€âˆ—
2
)>R2(Ï€
âˆ—
1
, Ï€2) âˆ€Ï€2 6= Ï€
âˆ—
2
41 / 46
Asymmetric Evolutionary Games
It follows from this definition that any strong Nash equilibrium of
an asymmetric game is an ESS profile.
Note that it is not clear at this stage that an ESS profile has to
satisfy this condition, e.g. no profile with a mixed strategy can
satisfy this condition. It will be argued that no such profile can be
an ESS in an asymmetric game.
42 / 46
Example 3.9.1
Consider the asymmetric Hawk-Dove game in which Player 1 is the
owner and Player 2 is an intruder.
Since (H, D) and (D, H) are strong Nash equilibria of this game,
they are ESS profiles.
The first ESS profile is the intuitively appealing â€be aggressive
when you are the owner, but avoid fights when you are an
intruderâ€.
The second ESS profile is the less intuitive â€avoid fights when you
are the owner, but be aggressive when you are an intruderâ€.
43 / 46
Example 3.9.1
The only other possible ESS profile corresponds to the mixed Nash
equilibrium in which both players play H with probability p
âˆ— =
v
c
.
Suppose that occupiers play Hawk with probability p and intruders
play H with probability q.
The expected payoff of an occupier who plays H is
R1(H, qH + (1 âˆ’ q)D) = 0.5q(v âˆ’ c) + (1 âˆ’ q)v.
44 / 46
\subsection{Example 3.9.1}
The expected payoff of an occupier who plays D is
R1(D, qH + (1 âˆ’ q)D) = 0.5(1 âˆ’ q)v.
Comparing these two expected payoffs, occupiers playing Hawk
obtain a higher payoff than occupiers playing Dove if q <
v
c
.
i.e. if the level of aggression in intruders is low, then owners should
be aggressive.
It follows from the symmetry of the payoffs that intruders playing
Hawk obtain a higher payoff than intruders playing Dove if p <
v
c
(i.e. the level of aggression in owners is low).
%% 45 / 46
%% Example 3.9.1
Suppose occupiers play H with probability v
c + Î´ and intruders play
H with probability v
% c âˆ’ , where Î´,  > 0.
It follows that selection will favour occupiers playing H and
intruders playing D.
It can be seen that evolution will take the population away from
the mixed Nash equilibrium. Hence, the mixed Nash equilibrium is
not an ESS.
46 / 46
\end{document}