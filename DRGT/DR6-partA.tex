
\documentclass[]{article}
\voffset=-1.5cm
\oddsidemargin=0.0cm
\textwidth = 480pt


\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{multicol}
%\usepackage[paperwidth=21cm, paperheight=29.8cm]{geometry}
%\usepackage[angle=0,scale=1,color=black,hshift=-0.4cm,vshift=15cm]{background}
%\usepackage{multirow}
\usepackage{enumerate}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{color}
\usepackage{multirow}
\usepackage{eurosym}
\usepackage{framed}

%\input def.tex
%\input dsdef.tex
%\input rgb.tex

%\newcommand \la{\lambda}
%\newcommand \al{a}
%\newcommand \be{b}
\newcommand \x{\overline{x}}
\newcommand \y{\overline{y}}

\begin{document}
	%%- David Ramsey 3.4
	\section{Concepts of Solutions to 2-Player Matrix Games - Minimax Solutions}
	\begin{itemize}
		\item The minimax strategy of a player is the strategy that maximises
		their expected payoff under the assumption that the other player
		aims to minimise this payoff.
		\item The minimax payoff of a player is the maximum expected payoff
		that they can guarantee themselves.
		\item In zero-sum games such a concept seems very reasonable, since by
		minimising the expected reward of the opponent, an individual
		maximises their expected reward.
	\end{itemize}
	
	%% 1 / 61
	\subsection{Minimax Solutions}
	One way of finding a player’s minimax strategy is to use linear
	programming.
	Suppose players choose one of two actions. In this case you can
	think of the strategy of a player as the probability of playing the
	first action, i.e. choice from the interval [0, 1]. The simplest
	method of solution is to use calculus.
	Denote the reward of Player i when Player 1 uses strategy p and
	Player 2 uses strategy q by Ri(p, q).
	% 2 / 61
	%=================================================%
	\subsection{Minimax Solutions - Example 3.4.1}
	Find the minimax strategies and payoffs in the following matrix
	game
	%A B
	%A (5,3) & (2,6) \\
	%B (3,2) & (4,5)\\
	
	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
				\cline{3-4}
				\multicolumn{2}{c|}{} & Keep Quiet         & Confess        \\
				\cline{2-4}
				\multirow{2} {*} {{\color{red}Player 1}}& Keep Quiet & (5,3) & (2,6) \\
				\cline{2-4}
				& Confess & (3,2) & (4,5)\\
				\cline{2-4}
				%C & (2,6) & (4,7)& (0,8) \\
				%\hline
			\end{tabular}
		}
	\end{center}
	
	%%- 3 / 61
	%=================================================%
	\subsection{Minimax Solutions - Example 3.4.1}
	\begin{itemize}
		\item Suppose Player 1 takes action A with probability p and Player 2
		takes action A with probability q. The expected reward of Player 1
		is given by
		\[R1(p, q) = 5pq+2p(1−q)+3(1−p)q+4(1−p)(1−q) = 4pq−2p−q+4.\]
		\item Player 1 assumes that Player 2 will minimise her payoff. 
		\item In order to
		derive which strategy of Player 2 minimises Player 1’s payoff, we
		calculate $\frac{\partial R1(p, q)}{\partial q}$
		(i.e. the rate of change of Player 1’s expected
		payoff with respect to the strategy of Player 2).
		\[\frac{\partial R1(p, q)}{\partial q} = 4p − 1.\]
		\item	In general, this derivative will be a linear function of p.
	\end{itemize}
	
	%%- 4 / 61
	%============================================%
	\subsection{Minimax Solutions - Example 3.4.1}
	There are three possibilities
	\begin{enumerate}
		\item  $\frac{\partial R1(p,q)}{\partial q}$ > 0 for all $p \in [0, 1]$. In this case to minimise
		Player 1’s payoff, Player 2 should play q = 0 (i.e.
		always take his second action). The minimax strategy
		of Player 1 is to take the action that maximises her
		reward when Player 2 takes his second action.
		\item  $\frac{\partial R1(p,q)}{\partial q}$ < 0 for all $p \in [0, 1]$. In this case to minimise
		Player 1’s payoff, Player 2 should play q = 1 (i.e.
		always take his first action). The minimax strategy of
		Player 1 is to take the action that maximises her
		reward when Player 2 takes his first action.
		\item There exists some $p \in [0, 1]$ such that $\frac{\partial R1(p,q)}{\partial q}$ = 0.
		When Player 1 uses this strategy, her expected payoff
		does not depend on the strategy used by Player 2.
		This is her minimax strategy.
	\end{enumerate}
	
	5 / 61
	%=================================================%
	% \subsection{Minimax Solutions - Example 3.4.1}
	\[ \partial R1(p, q)
	\partial q
	= 0 \rightarrow p =
	1
	4
	.\]
	We have
	\[R1(
	1
	4
	, q) = 4 − 2p = 3.5\].
	It follows that the minimax strategy of Player 1 is to choose action
	A with probability 0.25. In this way she guarantees herself a payoff
	of 3.5
	%% 6 / 61
	%=================================================%
	% \subsection{Minimax Solutions - Example 3.4.1}
	\begin{itemize}
		\item It should be noted that if Player 1 chose p >
		1
		4
		, then $\frac{\partial R1(p,q)}{\partial q}$ > 0
		and Player 2 minimises Player 1’s reward by choosing q = 0, i.e.
		Playing B.
		\item In this case the payoff of Player 1 would be
		\[R1(p, 0) = 4 − 2p < 3.5.\]
		\item 	Similarly, if Player 1 chose p <
		1
		4
		, then $\frac{\partial R1(p,q)}{\partial q}$ < 0 and Player 2
		minimises Player 1’s reward by choosing q = 1, i.e. Playing A.
		\item 	In this case the payoff of Player 1 would be
		R1(p, 1) = 2p + 3 < 3.5.
		\item  It is thus clear that 3.5 is the maximum
		expected payoff that Player 1 can guarantee herself.
	\end{itemize}
	
	%% 7 / 61
	%=================================================%
	% \subsection{Minimax Solutions - Example 3.4.1}
	We can calculate the minimax strategy of Player 2 in an analogous
	way, by deriving his expected payoff as a function of p and q and
	differentiating with respect to p, the strategy of Player 1. We have
	\[R2(p, q) = 3pq+6p(1−q)+2(1−p)q+5(1−p)(1−q) = p−3q+5.\]
	Hence,
	\[\partial R2(p, q)
	\partial p
	= 1 > 0.\]
	It follows that Player 1 always minimises Player 2’s expected
	reward by playing p = 0, i.e. always taking action B.
	%% 8 / 61
	%=================================================%
	\subsection{Minimax Solutions - Example 3.4.1}
	\begin{itemize}
		\item If Player 1 takes action B, then Player 2 should take action B.
		This ensures him a payoff of 5.
		\item Note: It can be seen from the payoff matrix that if Player 1’s aim
		is to minimise Player 2’s payoff, then her action B dominates
		action A.
		\item This is due to the fact that Player 2’s reward is always smaller
		when Player 1 plays B, whatever action Player 2 takes.
	\end{itemize}
	
	%% 9 / 61
	%============================================%
	% \subsection{Minimax Solutions - Example 3.4.1}
	Suppose both players use their minimax strategies, i.e. Player 1
	chooses action A with probability 0.25 and Player 2 always chooses
	action B.
	The payoff of Player 1 is
	\[R1(0.25A + 0.75B, B) = 0.25 × 2 + 0.75 × 4 = 3.5.\]
	The payoff of Player 2 is
	\[R2(0.25A + 0.75B, B) = 0.25 × 6 + 0.75 × 5 = 5.25,\] i.e. the
	reward obtained by Player 2 is greater than his minimax payoff.
	In general, if a player’s minimax strategy is a pure strategy, when
	both players play their minimax strategies, he/she may obtain a
	greater expected payoff than his/her minimax payoff.
	%% 10 / 61
	%===========================================%
	\subsection{Concepts of Solutions to 2-Player Matrix Games - Pure
		Nash equilibria}
	A pair of actions $(A^{\ast},(B^{\ast})$ is a pure Nash equilibrium if
\[	R1(A^{\ast},(B^{\ast}) \geq R1(A, B^{\ast}) \]
\[	R2(A^{\ast},(B^{\ast}) \geq R2(A^{\ast}, B) \]
	for any action A available to Player 1 and any action B available
	to Player 2.
	\begin{itemize}
		\item That is to say that a pair of actions is a Nash equilibrium if neither
		player can gain by unilaterally changing their action (i.e. changing
		their action whilst the other player does not change their action).
		\item The value of the game corresponding to an equilibrium is the
		vector of expected payoffs obtained by the players.
	\end{itemize}
	
	%%- 11 / 61
	%=================================%
	% \subsection{Concepts of Solutions to 2-Player Matrix Games - Strong Nash equilibria}
	A pair of actions (A
	∗
	, B
	∗
	) is a strong Nash equilibrium if
	R1(A
	∗
	, B
	∗
	) > R1(A, B
	∗
	); R2(A
	∗
	, B
	∗
	) > R2(A
	∗
	, B).
	for any action A 6= A
	∗
	available to Player 1 and any action B 6= B
	∗
	available to Player 2.
	i.e. a pair of actions is a strong Nash equilibrium if both players
	would lose by unilaterally changing their action.
	Any Nash equilibrium that is not strong is called weak.
	%% 12 / 61
	%================================%
	\subsection{Concepts of Solutions to 2-Player Matrix Games - Mixed
		Nash equilibria}
	A pair of mixed strategies, denoted (M1, M2) is a mixed Nash
	equilibrium if
	\[R1(M1, M2) \geq R1(A, M2); R2(M1, M2) \geq R2(M1, B)\]
	for any action (pure strategy) A available to Player 1 and any
	action B available to Player 2.
	\begin{itemize}
		\item It should be noted that the expected reward Player 1 obtains when
		he plays a mixed strategy M against M2 is a weighted average of
		the expected rewards of playing his pure actions against M2, where
		the weights correspond to the probability of playing each action.
		\item It follows that player 1 cannot do better against M2 than by using
		the best pure action against M2, i.e. if Player 1 cannot gain by
		switching to a pure strategy, then she cannot gain by switching to
		any mixed strategy.
	\end{itemize}
	
	%%- 13 / 61
	%================================%
	\subsection{The Bishop-Cannings Theorem}
	\begin{itemize}
		\item The support of a mixed strategy M1 is the set of actions that are
		played with a positive probability under M1.
		\item Suppose (M1, M2) is a Nash equilibrium pair of mixed strategies
		and the support of M1 is S. We have
		R1(A, M2) = R1(M1, M2), $\forall A  \in S$; R1(B, M2) < R1(M1, M2), $\forall B  \in S$.
		\item This is intuitively clear, since if a player uses actions A and B
		under a mixed strategy, then at equilibrium these actions must give
		the same expected reward, otherwise one action would be preferred
		over the other.
		\item It follows that at such an equilibrium all actions in the support of
		M1 must give the same expected reward, which thus has to be
		equal to the expected reward of using M1 (which is calculated as a
		weighted average). Thus all mixed Nash equilibria are weak.
	\end{itemize}
	
	%%- 14 / 61
	%================================%
	\subsection{Nash Equilibria - Results}
	\begin{itemize}
		\item Every matrix game has at least one Nash equilibrium.
		\item If there is a unique pure Nash equilibrium of a 2 × 2 game (i.e. a
		game in which both players have just 2 possible actions), then that
		is the only Nash equilibrium.
		\item If there are no or two strong Nash equilibria in such a game, then
		there is always a mixed Nash equilibrium.
		\item Mixed Nash equilibria can be found using the Bishop-Cannings
		theorem.
	\end{itemize}
	
	%%- 15 / 61
	%================================%
	\subsection{Symmetric Games}
	A game is symmetric if
\begin{enumerate}
	1. Players all choose from the same set of actions.
	2. R1(A, B) = R2(B, A).
\end{enumerate}
	Note that the symmetric Hawk-Dove game satisfies these
	conditions.
	%%- 16 / 61
	%================================%
	% \subsection{Symmetric Games}
\begin{itemize}
\item	If (A, B) is a pure Nash equilibrium in a symmetric game, then
	(B, A) is also a pure Nash equilibrium.
\tiem	At a mixed Nash equilibrium or minimax solution of a symmetric
	2 × 2 game, the players use the same strategy as each other.
\end{itemize}	%%- 17 / 61
	%=================================================%
	\subsection{Nash Equilibria - Example 3.4.2}
	Derive all the Nash equilibrium of the following game
	H D
	H (-2,-3) (4,0)
	D (0,4) (3,1)
	%%- 18 / 61
	%=================================================%
	% \subsection{Nash Equilibria - Example 3.4.2}
	The pure Nash equilibria can be found by checking every possible
	pair of actions.
	\begin{itemize}
		\item (H, H) is not a Nash equilibrium as either player would prefer to
		unilaterally change their action to D (and hence obtain 0 rather
		than -2 or -3).
		\item (D, D) is not a Nash equilibrium as either player would prefer to
		unilaterally change their action to H (and hence obtain 4).
		\item (H, D) is a Nash equilibrium, since if Player 1 switches to D, she
		obtains 3 not 4. If Player 2 switches to H, he obtains -3 not 0.
		\item	The value corresponding to this equilibrium is (4, 0).
		\item	Similarly, (D, H) is a Nash equilibrium. The value corresponding to
		this equilibrium is (0, 4).
	\end{itemize}
	
	%% 19 / 61
	%=================================================%
	%% \subsection{Nash Equilibria - Example 3.4.2}
	\begin{itemize}
		\item To find the mixed Nash equilibrium, we use Bishop-Cannings
		theorem. Suppose the strategy of Player 1 at equilibrium is
		pH + (1 − p)D . 	\item Player 2 must be indifferent between his two
		actions. Hence,
		\[R2(pH + (1 − p)D, H) = R2(pH + (1 − p)D, D) = v2,\]
		where v2 is the value of the game to Player 2 .
		\item We thus have \[−3p + 4(1 − p) = 0p + 1(1 − p) = v2.\] Solving these
		equations gives p = 0.5, v2 = 0.5.
	\end{itemize}
	
	%% 20 / 61
	%=================================================%
	% \subsection{Nash Equilibria - Example 3.4.2}
	Similarly, suppose the strategy of Player 2 at equilibrium is
	$qH + (1 − q)D$. Player 1 must be indifferent between his two
	actions. Hence,
	\[R1(H, qH + (1 − q)D) = R1(D, qH + (1 − q)D) = v1.\]
	We thus obtain −2q + 4(1 − q) = 0q + 3(1 − q) = v1. Solving
	these equations gives q =
	1
	3
	, v1 = 2.
	Hence, the mixed equilibrium is (0.5H + 0.5D, 1/3H + 2/3D). The
	corresponding value is (2, 0.5).
	%% 21 / 61
	%=================================================%
	\subsection{Advantages of the Concept of Minimax Strategies}
	\begin{enumerate}
		\item  A player only has to know his own payoffs in order to
		determine his/her minimax strategy and payoff.
		\item  Apart from degenerate cases (e.g. two actions always
		give the same payoff), there is a unique minimax
		strategy.
		\item  In the case of fixed-sum games, it seems eminently
		reasonable to follow a minimax strategy.
	\end{enumerate}
	
	%% - 22 / 61
	%=================================================%
	\subsection{Disadvantages of the Concept of Minimax Strategies}
	\begin{enumerate}
		\item  Although the minimax value of a game is well
		defined, when both players play their minimax
		strategy their vector of expected payoffs is not
		necessarily the minimax value of the game (i.e. when
		both players play the strategy that maximises their
		guaranteed expected reward, one or more of the
		players may obtain more than this guaranteed
		minimum).
		\item Many situations cannot be described in terms of pure
		competition (i.e. in terms of a fixed-sum game). In
		such cases, the assumption that the aim of an
		opponent is to minimise a player’s expected reward
		may well be unreasonable.
	\end{enumerate}
	
	%%- 23 / 61
	%============================================%
	\subsection{Advantages of the Concept of Nash Equilibria}
	\begin{enumerate}
		\item  In fixed sum games, the unique Nash Equilibrium pair
		of strategies is equal to the pair of minimax
		strategies.
		\item  In non-fixed sum games, the Nash equilibrium
		concept makes the more reasonable assumption that
		both players wish to maximise their own reward.
		\item  When using the concept of Nash equilibrium it is
		normally assumed that players know the payoff
		functions of their opponents.
\item  However, in order to
		find a pure Nash equilibrium, it is only necessary to
		be able to order the preferences of opponents, not
		their actual payoffs.
	\end{enumerate}
	
	%%- 24 / 61
	%============================================%
	\subsection{Disadvantages of the Concept of Nash Equilibria}
	\begin{enumerate}
		\item There may be multiple equilibria of a game, so the
		concept of Nash equilibrium should be strengthened
		in order to make predictions in such situations.
		\item Unlike in the derivation of minimax strategies, it is
		assumed that the payoff functions of opponents are
		known. This information is necessary to derive a
		mixed Nash equilibrium.
		\item  The concept of a Nash equilibrium requires that a
		player maximises his/her reward given the behaviour
		of opponents. However, this behaviour is not known
		a priori.
	\end{enumerate}
	
	%%- 25 / 61
	%============================================%
	\subsection{3.5 Actions Dominated by Pure Strategies}
\begin{itemize}
	\item 	Suppose that by taking action Ai Player 1 always gets at least the
	same reward as by playing Aj , regardless of the action taken by
	Player 2, and for at least one action of Player 2 he obtains a
	greater reward. 
	\item Action Ai of Player 1 is said to dominate action Aj	.
	i.e. action Ai of Player 1 dominates Aj
	if
\end{itemize}

\[	R1(Ai
	, Bk ) \geq R1(Aj
	, Bk ), k = 1, 2, . . . , n\]
	and for some k0, \[R1(Ai
	, Bk0
	) > R1(Aj
	, Bk0
	).\]
%%	26 / 61
	%=================================================%
	\subsubsection{Actions Dominated by Pure Strategies}
	Similarly, action Bi of Player 2 dominates action Bj
	if
\[	R2(Ak , Bi) \geq R2(Ak , Bj), k = 1, 2, . . . , m\]
	and for some k0
	R2(Ak0
	, Bi) > R2(Ak0
	, Bj).
	%%- 27 / 61
	%============================================%
	\subsection{Actions Dominated by Randomised Strategies}
	When removing dominated strategies, it is easiest to first remove
	those that are dominated by pure strategies.
	Once that is done we then remove those that are dominated by
	randomised strategies.
	The following statements are important in determining which
	strategies may be dominated by a randomised strategy.
	%% 28 / 61
	%============================================%
	%%- \subsection{Actions Dominated by Randomised Strategies}
	If Ai
	is Player 1’s unique best response to Bj
	, then Ai cannot be
	dominated by any strategy, pure or randomised.
	Thus, if ∃Bk such that R1(Ai
	, Bk ) > R1(Aj
	, Bk ), ∀j 6= i, then Ai
	cannot be dominated.
	Similarly, if Bi
	is Player 2’s unique best response to Aj
	, then Bi
	cannot be dominated.
	%%- 29 / 61
	%============================================%
	%%- \subsection{Actions Dominated by Randomised Strategies}
	Player 1’s mixed strategy p1Ai1 + p2Ai2 + . . . + plAil
	dominates Aj
	,
	j 6= is for any s = 1, 2, ...l, if for all Bk
	\[R1(p1Ai1 + p2Ai2 + . . . + plAil
	, Bk ) \geq R1(Aj
	, Bk )\]
	and this inequality is strict for at least one value of k.
	Similarly, Player 2’s mixed strategy q1Bi1 + q2Bi2 + . . . + qlBil
	dominates Bj
	, j 6= is for any s = 1, 2, ...l, if for all Ak
	\[R2(Ak , q1Bi1 + q2Bi2 + . . . + qlBil
	) \geq R2(Ak , Bj)\]
	and this inequality is strict for at least one value of k.
	%%- 30 / 61
	%============================================%
	\subsection{Successive removal of dominated actions}
	\begin{itemize}
		\item It is clear that an individual should not use a dominated action.
		Hence, we may remove such actions from the payoff matrix without
		changing either the minimax strategies or the Nash equilibria.
		\item	It should be noted that an action that was not previously
		dominated may become dominated after the removal of dominated
		strategies.
		\item Hence, we continue removing dominated strategies until there are
		no dominated strategies left in the reduced game (see tutorial and
		following example).
	\end{itemize}
	
	%% 31 / 61
\end{document}
