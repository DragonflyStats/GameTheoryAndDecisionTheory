\documentclass[a4paper,12pt]{article}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{framed}
\usepackage{multicol}
%\usepackage[paperwidth=21cm, paperheight=29.8cm]{geometry}
%\usepackage[angle=0,scale=1,color=black,hshift=-0.4cm,vshift=15cm]{background}
%\usepackage{multirow}
\usepackage{enumerate}

\usepackage{amsmath,amsfonts,amssymb}
\usepackage{color}
\usepackage{multirow}
\usepackage{eurosym}
\usepackage{framed}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{eurosym}
\usepackage{vmargin}
\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{framed}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{fancyhdr}

%\input def.tex
%\input dsdef.tex
%\input rgb.tex

%\newcommand \la{\lambda}
%\newcommand \al{a}
%\newcommand \be{b}
\newcommand \x{\overline{x}}
\newcommand \y{\overline{y}}

\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
\lhead{Operations Research 2} \rhead{Kevin O'Brien}
\chead{MS4315}
%\input{tcilatex}

\begin{document}
\section{Outcomes}
\begin{itemize}
	\item An outcome is a situation which results from a combination of player's strategies. Every combination of strategies (one for each player) is an outcome of the game. A primary purpose of game theory is to determine which outcomes are stable according to a solution concept (e.g. Nash equilibria).
	\item 
	In a game where chance or a random event is involved, the outcome is not known from only the set of strategies, but is only realized when the random event(s) are realized.
	\item 
	A set of payoffs can be considered a set of N-tuples, where N is the number of players in the game, and the cardinality of the set is equal to the total number of possible outcomes when the strategies of the players are varied. The payoff set can thus be partially ordered, where the partial ordering comes from the value of each entry in the tuple. 
	% How players interact to allocate the payoffs among themselves is a fundamental aspect of economics.
\end{itemize}
%\section{Non-Cooperative Game}
%A non-cooperative game is one in which players are unable to make enforceable contracts outside of those specifically modeled in the game. Hence, it is not defined as games in which players do not cooperate, but as games in which any cooperation must be self-enforcing. Games in which players can enforce contracts through outside parties are termed cooperative games.

%=======================================================%
\section{Strictly Determined Games}
A strictly determined game is a two-player zero-sum game that has at least one \textbf{Nash equilibrium} with both players using pure strategies. The value of a strictly determined game is equal to the value of the equilibrium outcome.

\begin{framed}
	If there is an entry in the payoff matrix that is simultaneously the smallest entry in its row and
	the largest entry in its column, we call that point a saddle point. If a payoff matrix has a saddle point, we say that the game is \textbf{\textit{strictly determined}}. The saddle point is also called the value of the game.
	\begin{itemize}
		\item If the value of the game is positive, then the game favors the row player.
		\item If the value of the game is negative, then the game favors the column player.
		\item If the value of the game is zero, then the game is fair.
	\end{itemize}
\end{framed}

\section{Dominance}
In game theory, dominance occurs when one strategy is better than another strategy for one player, no matter how that player's opponents may play. Many simple games can be solved using dominance. The opposite, \textbf{\textit{intransitivity}}, occurs in games where one strategy may be better or worse than another strategy for one player, depending on how the player's opponents may play.
\newpage
%--------------------------------------------------------%
\subsection{Terminology}
When a player tries to choose the ``best" strategy among a multitude of options, that player may compare two strategies A and B to see which one is better. The result of the comparison is one of:
\begin{itemize}
	\item B dominates A: choosing B always gives as good as or a better outcome than choosing A. There are 2 possibilities:
	\begin{enumerate}
	\item B strictly dominates A: choosing B always gives a better outcome than choosing A, no matter what the other player(s) do.
	\item B weakly dominates A: There is at least one set of opponents' action for which B is superior, and all other sets of opponents' actions give B the same payoff as A.
	\end{enumerate}
	\item B and A are intransitive: B neither dominates, nor is dominated by, A. Choosing A is better in some cases, while choosing B is better in other cases, depending on exactly how the opponent chooses to play. \\ \textit{For example, B is ``throw rock" while A is "throw scissors" in Rock, Paper, Scissors.}
	\item B is dominated by A: choosing B never gives a better outcome than choosing A, no matter what the other player(s) do. There are 2 possibilities:
	\begin{enumerate}
	\item B is weakly dominated by A: There is at least one set of opponents' actions for which B gives a worse outcome than A, while all other sets of opponents' actions give A the same payoff as B. (Strategy A weakly dominates B).
	\item B is strictly dominated by A: choosing B always gives a worse outcome than choosing A, no matter what the other player(s) do. (Strategy A strictly dominates B).
	\end{enumerate}
\end{itemize}
\medskip
This notion can be generalized beyond the comparison of two strategies.

\begin{itemize}
	\item Strategy B is strictly dominant if strategy B strictly dominates every other possible strategy.
	\item Strategy B is weakly dominant if strategy B dominates all other strategies, but some (or all) strategies are only weakly dominated by B.
	\item Strategy B is strictly dominated if some other strategy exists that strictly dominates B.
	\item Strategy B is weakly dominated if some other strategy exists that weakly dominates B.
\end{itemize}
\newpage
%==========================================================%
\section{Nash Equilibrium}
Nash equilibrium is a solution concept of a non-cooperative game involving two or more players in which each player is assumed to know the equilibrium strategies of the other players, and no player has anything to gain by changing only their own strategy.
If each player has chosen a strategy and no player can benefit by changing strategies while the other players keep theirs unchanged, then the current set of strategy choices and the corresponding payoffs constitutes a Nash equilibrium. 

\begin{framed}
\begin{itemize}
\item Nash Equilibrium recommends a strategy to each player that the player cannot improve upon unilaterally, as long as the other players follow the recommendation.
\item Since the other players are assumed to be rational, it is reasonable to expect the opponents to follow the recommendation as well.
\end{itemize}
\end{framed}

%===========================================================%

\subsection{Informal definition}
\begin{itemize}
\item Informally, a strategy profile is a Nash equilibrium if no player can do better by unilaterally changing their strategy. To see what this means, imagine that each player is told the strategies of the others. Suppose then that each player asks themselves: \textit{"Knowing the strategies of the other players, and treating the strategies of the other players as set in stone, can I benefit by changing my strategy?"}
\item If any player could answer ``Yes", then that set of strategies is not a Nash equilibrium. But if every player prefers not to switch (or is indifferent between switching and not) then the strategy profile is a Nash equilibrium. Thus, each strategy in a Nash equilibrium is a best response to all other strategies in that equilibrium.
%\item The Nash equilibrium may sometimes appear non-rational in a third-person perspective. This is because it may happen that a Nash equilibrium is not Pareto optimal.
%\item The Nash equilibrium may also have non-rational consequences in sequential games because players may "threaten" each other with non-rational moves. For such games the subgame perfect Nash equilibrium may be more meaningful as a tool of analysis.
\item Nash Equilibrium can also be thought of as ``no regrets," in the sense that once a decision is made, the player will have no regrets concerning decisions considering the consequences.
 
\item The Nash Equilibrium is reached over time, in most cases. However, once the Nash Equilibrium is reached, it will becoming self-enforcing. %After we learn how to find the Nash Equilibrium, take a look at how a unilateral move would affect the situation. Does it make any sense? It shouldn't, and that's why the Nash Equilibrium is described as ``no regrets."
\end{itemize}
%\newpage
%%----------------------------------------%
%\section{The Nash Equilibrium}
%Nash Equilibrium is an outcome reached that, once achieved, means no player can increase payoff by changing decisions unilaterally.
\newpage
\section{Finding a Nash Equilibria}
%-http://www.investopedia.com/articles/financial-theory/09/game-theory-beyond-basics.asp
Consider the following matrix game.
\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Left       &  Right       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Player 1}}& Up & (1,3) & (4,2) \\
			\cline{2-4}
			& Down &(3,2)& (3,1) \\
			\cline{2-4}
			
		\end{tabular}
	}
\end{center}

\subsection{Step One: Determine player one's best response to player two's actions.}
When examining the choices that may maximize a player's payout, we must look at how player one (i.e. you) should respond to each of the options player two has. An easy way to do this visually is to cover up the choices of player two. Consider the matrix portrayed above as we apply this method.



\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Left       &  Right       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Player 1}}& Up & (1,...) & (4,...) \\
			\cline{2-4}
			& Down &(3,...)& (3,...) \\
			\cline{2-4}
			
		\end{tabular}
	}
\end{center}
\begin{itemize}
	\item Player one has two possible choices to play: ``up" or ``down." Player two also has two choices to play: ``left" or ``right." In this step of determining Nash Equilibrium, we look at responses to player two's actions.
	\item  If player two chooses to play ``left," we can play ``up" with the payoff of one, or play ``down" with the payoff of three. Since three is greater than one, we will bold the 3 indicating the option to play ``down" here.
	
	\item If player two chooses to play ``right," we can either choose to play 'up' for a payoff of four or play ``down" for a playoff of three. Since four is greater than three, we bold the four to indicate the option to play ``up" here. The bold outcomes are shown below on the full matrix.
	
\end{itemize}

%========================================================================%	

\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Left       &  Right       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Player 1}}& Up & (1, 3)	& (\underline{\textbf{4}}, 2) \\
			\cline{2-4}
			& Down &(\underline{\textbf{3}}, 2)	& (3, 1)\\
			\cline{2-4}
			%C & (2,6) & (4,7)& (0,8) \\
			%\hline
		\end{tabular}
	}
\end{center}


%========================================================================%
\subsection{Step Two: Determine Player Two's best response to Player one's actions.}
As we did before with the player two payoffs for player one, we will hide the payoffs of player one when determining the best responses for player two. 
\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Left       &  Right       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Player 1}}& Up & (..., 3) &	(..., 2) \\
			\cline{2-4}
			& Down &(..., 2) & 	(..., 1) \\
			\cline{2-4}
			
		\end{tabular}
	}
\end{center}

\begin{itemize}
\item 
Just as when looking at player one, each player has two choices to play. If player one chooses to play "up," Player 2 can play ``left," with a payoff of three, or ``right," with a payoff of two.
\item Since three is greater than two, we bold the three to show the option to play ``left" here. 
\item If player one chooses to play ``down," player 2 can play ``left," for a payoff of two, or ``right," for a payoff of one. \item Since two is greater than one, we bold the two indicating the option to play ``left" here. 
\item The bold outcomes are shown below on the full matrix.
\end{itemize}
\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Left       &  Right       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Player 1}}& Up & (1, \underline{\textbf{3}}) &	(4, 2) \\
			\cline{2-4}
			& Down &(3, \underline{\textbf{2}}) & 	(3, 1) \\
			\cline{2-4}
			
		\end{tabular}
	}
\end{center}


\subsection{Step Three: Determine which outcomes have both payoffs bold.} 
That particular outcome is the Nash Equilibrium.Now, we combine the bold options for both players onto the full matrix.

\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Up      &  Down       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Player 1}}& Up & (1,3) & (4,2) \\
			\cline{2-4}
			& Down &(\underline{\textbf{3,2}})& (3,1) \\
			\cline{2-4}
			%C & (2,6) & (4,7)& (0,8) \\
			%\hline
		\end{tabular}
	}
\end{center}



Look for intersections where both payoffs are bold. In this case, we find the intersection of (Down , Left) with the payoff of (3, 2) fits our criteria. This indicates our Nash Equilibrium.

\newpage
\subsection{Airline Example}
Below is an example, similar to the game above, of how airline pricing may play out. The payouts are in thousands of dollars. Remember, these are the payouts, not the prices. The method we applied previously is already applied to show where the Nash Equilibrium appears.

%%Airline one / Airline two	Low Price	High Price
%%Low Price	(3,000, 3,000) &	(4,000, 2,000) \\
%%High Price	(2,000, 4,000) &	(3,500, 3,500) \\

\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Airline 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Low Price       &  High Price      \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Airline 1}}& Low Price & (3,000, 3,000) &	(4,000, 2,000) \\
			\cline{2-4}
			& High Price & (2,000, 4,000) &	(3,500, 3,500) \\
			\cline{2-4}
			%C & (2,6) & (4,7)& (0,8) \\
			%\hline
		\end{tabular}
	}
\end{center}
\begin{itemize}	
	\item Looking at just A1's choices we can see that if A2 chooses to play low price, we choose between Low Price for 3,000 or high price for 2,000. We choose ``low," since $3,000>2,000$. 
	\item We do the same thing for A2 playing High Price and see that we play ``low" because $4,000>3,500$. 
	\item Conversely, looking just at A2's choices, we can see that if A1 chooses to play low price, A2 can choose between ``low price" for 3,000 and "high price" for 2,000. 
	\item Since $3,000>2,000$, we choose the ``low price" option here.\item  If A1 plays high price, A2 can charge a low price for 4,000 or high price for 3,500. Since $4,000>3,500$, A2 will choose to play \textit{"low price"} here.
\end{itemize}

\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Airline 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Low Price       &  High Price      \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Airline 1}}& Low Price & \underline{\textbf{(3,000, 3,000)}} &	(4,000, 2,000) \\
			\cline{2-4}
			& High Price & (2,000, 4,000) &	(3,500, 3,500) \\
			\cline{2-4}
			%C & (2,6) & (4,7)& (0,8) \\
			%\hline
		\end{tabular}
	}
\end{center}
%=======================================%
\begin{itemize}
	\item The Nash Equilibrium is that both airlines will charge a low price (shown when choices for each party are highlighted). If both airlines charged a high price, they would each be better off than they are at the Nash Equilibrium.
	
	\item So why don't they agree to do this? (\textit{In reality, it's illegal to collude.)} If this were to occur, a unilateral action on behalf of one airline to charge a low price would be beneficial, resulting in that airline making more money in turn. 
	\item This logic also shows how the Nash Equilibrium is reached, and why it is not beneficial to deviate from it once it is reached. 
\item Suppose both Airlines are using the ``Low Strategy". Then suppose that Airline 1 unilaterally changes to a ``high" strategy. (4000 for Airline 1, 2000 for Airline 2). However, the same course of action is available to Airline 2. 


\end{itemize}
\newpage
\section{Finding Nash Equilibria - Another Case}

Consider, for example, the game


\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   Left       &  Right       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Player 1}}& Top & (2,2) & (0,3) \\
			\cline{2-4}
			& Bottom &(3,0)& (1,1) \\
			\cline{2-4}
			%C & (2,6) & (4,7)& (0,8) \\
			%\hline
		\end{tabular}
	}
\end{center}
%===========================================================================%
There are four action profiles $((T,L), (T,R), (B,L), and (B,R))$; we can examine each in turn to check whether it is a Nash equilibrium.
\begin{itemize}
	\item \textbf{(T,L)}
	By choosing B rather than T, player 1 obtains a payoff of 3 rather than 2, given player 2's action. Player 2 also can increase their payoff (from 2 to 3) by choosing R rather than L. Thus (T,L) is not a Nash equilibrium.
	\item \textbf{(T,R)}
	By choosing B rather than T, player 1 obtains a payoff of 1 rather than 0, given player 2's action. Thus (T,R) is not a Nash equilibrium.
	\item \textbf{(B,L)}
	By choosing R rather than L, player 2 obtains a payoff of 1 rather than 0, given player 1's action. Thus (B,L) is not a Nash equilibrium.
	\item \textbf{(B,R)}
	Neither player can increase their payoff by choosing an action different from their current one. Thus this action profile is a Nash equilibrium.
\end{itemize}
We conclude that the game has a unique Nash equilibrium, (B,R).
Notice that in this equilibrium both players are worse off than they are in the action profile (T,L). Thus they would like to achieve (T,L); but their individual incentives point them to (B,R).


%==========================================================%
\begin{framed}
	\begin{itemize}
		\item A Nash equilibrium of a strategic game is an action profile (list of actions, one for each player) with the property that no player can increase their payoff by choosing a different action, given the other players' actions.
		\item Note that nothing in the definition suggests that a strategic game necessarily has a Nash equilibrium, or that if it does, it has a single Nash equilibrium. 
		\item A strategic game may have no Nash equilibrium, may have a single Nash equilibrium, or may have many Nash equilibria.
	\end{itemize}
\end{framed}


\end{document}
%----------------------------------------%

\section{How to find a Nash Equilibrium in a $2 \times 2$ matrix}


\subsection{Dominant Strategy Method}
\begin{itemize}
\item Check each column for Player 1’s highest payoff, this is their best choice given Column player’s choice.  \textit{(if there are two high choices, then the result will be a mixed strategy outcome).}
\item Now check to see if Row’s choice for (1) would also be their choice given any choice by Column player.
\item If Player 1 always sticks with their choice regardless of Player 2’s choice, this is their dominant strategy.
\item Repeat for Player 2, and the Nash equilibrium is where the dominant strategies intersect.
\end{itemize}

\subsection{Rule of Thumb Method}
\begin{itemize}
\item Choose one opponent’s choice and see if the player has an incentive to change their choice. 
\item If no, circle that payoff, if yes; check another cell within the same choice by the opponent.
\item Repeat for all choices for both players.
\item The Nash equilibrium (could be more than 1) occur where both payoffs are circled.
\end{itemize}
%========================================================%
\newpage
\subsection{Example}
\textbf{Constructing the payoff matrix, rules:}
\begin{itemize}
\item Consider a market dominated by two companies. The total market share is 10
\item Cost of advertising is 4 for high, 2 for low.
\item If companies both choose the same advertising level they split the market, but if one firm chooses high and the other low, than the firm that chose high advertising gets the entire market.
\end{itemize}

\begin{center}
	{\color{blue}
		\begin{tabular}{c|c|c|c|}
			\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Company 2}} \\
			\cline{3-4}
			\multicolumn{2}{c|}{} &   High       &  Low       \\
			\cline{2-4}
			\multirow{2} {*} {{\color{red}Company 1}}& High & (1,1) & (6,-2) \\
			\cline{2-4}
			& Low &(-2,6)& (3,3) \\
			\cline{2-4}
			%C & (2,6) & (4,7)& (0,8) \\
			%\hline
		\end{tabular}
	}
\end{center}
%- http://www.freeeconhelp.com/2012/02/how-to-find-nash-equilibrium-in-2x2.html
\subsection{Example of finding Nash equilibrium using the dominant strategy method:}
\begin{itemize}
\item We can first look at Player 1’s payoffs to see that if column chooses high, it is in Player 1’s best interest to choose high because $1>-2$, and if column choose low, row will also choose high because $6>3$.  
\item So choosing high is Player 1’s dominant strategy.  We can do the same analysis for column player to get the same result.  Since both players have a dominant strategy of choosing high, this will be a Nash equilibrium.
\end{itemize}
\subsection{Example of finding Nash equilibrium using rule of thumb method:}
\textbf{(Demonstrated in Class)}
\begin{itemize}
\item Let’s start with the first cell, and see if row player wants to switch choices.  Since $1>-2$, row player doesn’t want to switch, so we can circle that payoff . 
\item  The same method for column player shows that they would not want to switch as well so we can circle their payoff .  We can do the same analysis with each choice, to see where all of the circles should go.  \item The cell with both payoffs circled is a Nash equilibrium.  \item Remember that it is possible to have a payoff matrix with no Nash equilibrium.
\end{itemize}


\newpage
%=========================================%

\section{Multiple Nash Equilibria \& How The Nash Equilibrium Plays Out}
\begin{itemize}
\item Generally, there can be more than one equilibrium in a game. However, this usually occurs in games with more complex elements than two choices by two players. In simultaneous games that are repeated over time, one of these multiple equilibria is reached after some trial and error. 
\item This scenario of differing choices over time before reaching equilibrium is the most often played out in the business world when two firms are determining prices for very interchangeable products, such as airfare or soda pop.

With these advanced methods, more real-world situations can be modeled and solved. 
\item The different kinds of Nash Equilibrium we discussed are the most commonly found solutions to real-world modeled games. A working knowledge of Game Theory can help you form a strategy, whether playing a friend playing tic-tac-toe or vying for the largest profits.
\end{itemize}

\newpage

%==========================================================%

\subsection{Nash Equilibrium and Dominant Strategies}

Nash Equilibrium is a term used in game theory to describe an equilibrium where each player's strategy is optimal given the strategies of all other players. A Nash Equilibrium exists when there is no unilateral profitable deviation from any of the players involved. In other words, no player in the game would take a different action as long as every other player remains the same. Nash Equilibria are self-enforcing; when players are at a Nash Equilibrium they have no desire to move because they will be worse off.

Necessary Conditions

The following game doesn't have payoffs defined:

L	R
T	a,b	c,d
B	e,f	g,h
In order for (T,L) to be an equilibrium in dominant strategies (which is also a Nash Equilibrium), the following must be true:

a > e
c > g
b > d
f > h
In order for (T,L) to be a Nash Equilibrium, only the following must be true:
a > or = e
b > or = d
\subsection{Prisoners' Dilemma (Again)}

If every player in a game plays his dominant pure strategy (assuming every player has a dominant pure strategy), then the outcome will be a Nash equilibrium. The Prisoners' Dilemma is an excellent example of this. It was reviewed in the introduction, but is worth reviewing again. Here's the game (remember that in the Prisoners' Dilemma, the numbers represent years in prison):

Jack
C	NC
Tom	C	-10,-10	0,-20
NC	-20,0	-5,-5

%==========================================%
In this game, both players know that 10 years is better than 20 and 0 years is better than 5; therefore, C is their dominant strategy and they will both choose C (cheat). Since both players chose C, (10,10) is the outcome and also the Nash Equilibrium. To check whether this is a Nash Equilibrium, check whether either player would like to deviate from this position. Jack wouldn't want to deviate, because if he chose NC and Tom stayed at C, Jack would increase his prison time by 10 years.

\subsection{Iterated Deletion of Dominated Strategies}

Here's another game that doesn't have dominant pure strategies, but that we can solve by iterated deletion of dominated strategies. In other words, we can eliminate strategies that are dominated until we come to a conclusion:

2
Left	Middle	Right
1	Up	1,0	1,2	0,1
Down	0,3	0,1	2,0

%==========================================%
Let's find the dominant strategies. The first strategy that is dominated, is Right. Player 2 will always be better off by playing Middle, so Right is dominated by Middle. At this point the column under Right can be eliminated since Right is no longer an option. This will be shown by crossing out the column:

\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{3}{c} {{\color{red}Player 2}} \\
				\cline{3-5}
				\multicolumn{2}{c|}{} &   Heads      &  Tails & Right      \\
				\cline{2-5}
				\multirow{2} {*} {{\color{red}Player 1}}& Heads & 1 & -1 & \\
				\cline{2-5}
				& Tails &-1& 1&  \\
				\cline{2-5}
			
			\end{tabular}
		}
	\end{center}
2
Left	Middle	Right
1	Up	1,0	1,2	0,1
Down	0,3	0,1	2,0
%==========================================%
Remember that both players understand that player 2 has no reason to play Right--player 1 understands that player 2 is trying to find an optimum, so he also no longer considers the payoffs in the Right column. With the Right column gone, Up now dominates Down for player 1. Whether player 2 plays Left or Middle, player 1 will get a payoff of 1 as long as he chooses Up. So now we no longer consider Down:

2
Left	Middle	Right
\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{3}{c} {{\color{red}Player 2}} \\
				\cline{3-5}
				\multicolumn{2}{c|}{} &   Heads      &  Tails & Right      \\
				\cline{2-5}
				\multirow{2} {*} {{\color{red}Player 1}}& Heads & 1 & -1 & \\
				\cline{2-5}
				& Tails &-1& 1&  \\
				\cline{2-5}
			
			\end{tabular}
		}
	\end{center}
1	Up	1,0	1,2	0,1
Down	0,3	0,1	2,0

%==========================================%
Now we know that player 1 will choose Up, and player 2 will choose Left or Middle. Since Middle is better than Left (a payoff of 2 vs. 0), player 2 will choose Middle and we have solved the game for the Nash Equilibrium:

	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{3}{c} {{\color{red}Player 2}} \\
				\cline{3-5}
				\multicolumn{2}{c|}{} &   Heads      &  Tails & Right      \\
				\cline{2-5}
				\multirow{2} {*} {{\color{red}Player 1}}& Heads & 1 & -1 & \\
				\cline{2-5}
				& Tails &-1& 1&  \\
				\cline{2-5}
			
			\end{tabular}
		}
	\end{center}
2
Left	Middle	Right
1	Up	1,0	1,2	0,1
Down	0,3	0,1	2,0

%==========================================%
To ensure that this answer (Up, Middle) is a Nash Equilibrium, check to see whether either player would like to deviate. As long as player 1 has chosen Up, player 2 will choose Middle. On the other hand, as long as player 2 has chosen Middle, player 1 will choose up.

\subsection{Multiple Nash Equilibria}

Here's a game that demonstrates multiple Nash Equilibria: Two drivers are traveling towards each other on a road. Should they drive on the left or the right side? They don't want to wreck...

Driver 2
Left	Right
Driver 1	Left	1,1	-1,-1
Right	-1,-1	1,1
Both (Left,Left) and (Right,Right) are Nash Equilibria. As long as they're on opposite sides of the road, the drivers are happy and don't want to deviate. Games like this are often solved by social convention--beforehand all the players agree on a strategy so that everyone is better off. Of course, everyone knows that the right side is the best side to drive on, so the game should look more like this:

Driver 2
Left	Right
Driver 1	Left	1,1	-1,-1
Right	-1,-1	2,2
In this case, the game itself gives the players a clue as to where the other player will be, even though there are two Nash Equilibria.

Here's a game with three Nash Equilibria and no dominated strategies:

2
a	b	c
1	A	1,1	2,0	3,0
B	0,2	3,3	0,0
C	0,3	0,0	10,10
The Nash Equilibria are (A,a), (B,b), and (C,c).

%=============================================%

\subsection{Example of an iterated deletion of dominated strategy equilibrium}
\begin{itemize}
\item Consider the following game to better understand the concept of iterated elimination of strictly dominated strategies.
\item Player 1 has two strategies and player 2 has three. S1={up,down} and S2={left,middle,right}. For player 1, neither up nor down is strictly dominated. Up is better than down if 2 plays left (since 1>0), but down is better than up if 2 plays right (since 2>0). For player 2, however, right is strictly dominated by middle (since 2>1 and 1>0), so player 2 being rational will not play right.

\item Thus if player 1 knows that player 2 is rational then player 1 can eliminate right from player 2's strategy space. So, if player 1 knows that player 2 is rational then player 1 can play the game as if it was the game depicted below.

\item In the figure above, down is strictly dominated by up for player 1 , and so if player 1 is rational (and player 1 knows that player 2 is rational, so that the second game applies) then player 1 will not play down. Consequently, if player 2 knows that player 1 is rational, and player 2 knows that player 1 knows that player 2 is rational ( so that player 2 knows that the second game applies) then player 2 can eliminate down from player 1's strategy space, leaving the game looking like below.

\item 
And now left is strictly dominated by middle for player 2 , leaving (up,middle) as the outcome of the game. This is process is called the iterated elimination of strictly dominated strategies.
\end{itemize}
\end{document}
