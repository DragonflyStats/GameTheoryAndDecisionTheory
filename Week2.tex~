\documentclass[a4paper,12pt]{article}

\usepackage{amsmath}
\usepackage{graphicx}
\usepackage{amssymb}
\usepackage{framed}
%\usepackage{multicol}
%\usepackage[paperwidth=21cm, paperheight=29.8cm]{geometry}
%\usepackage[angle=0,scale=1,color=black,hshift=-0.4cm,vshift=15cm]{background}
%\usepackage{multirow}
\usepackage{enumerate}

\usepackage{amsfonts,amssymb}
\usepackage{color}
\usepackage{multirow}
\usepackage{eurosym}
\usepackage{framed}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{eurosym}
\usepackage{vmargin}
%\usepackage{amsmath}
\usepackage{fancyhdr}
\usepackage{listings}
\usepackage{multicols}
\usepackage{framed}
\usepackage{graphics}
\usepackage{epsfig}
\usepackage{subfigure}
\usepackage{fancyhdr}

%\input def.tex
%\input dsdef.tex
%\input rgb.tex

%\newcommand \la{\lambda}
%\newcommand \al{a}
%\newcommand \be{b}
\newcommand \x{\overline{x}}
\newcommand \y{\overline{y}}

\pagestyle{fancy}
\setmarginsrb{20mm}{0mm}{20mm}{25mm}{12mm}{11mm}{0mm}{11mm}
\lhead{Operations Research 2} \rhead{Game Theory}
\chead{MS4315}
%\input{tcilatex}

\begin{document}
\begin{framed}
\begin{multicols}{2}
\begin{itemize}
\item Strategy Types
\item Minimax 
\end{itemize}
\end{multicols}
\end{framed}


%========================================%
\section{Pure and mixed strategies}
A pure strategy provides a complete definition of how a player will play a game. In particular, it determines the move a player will make for any situation he or she could face. A player's strategy set is the set of pure strategies available to that player.

A mixed strategy is an assignment of a probability to each pure strategy. This allows for a player to randomly select a pure strategy. Since probabilities are continuous, there are infinitely many mixed strategies available to a player.

Of course, one can regard a pure strategy as a degenerate case of a mixed strategy, in which that particular pure strategy is selected with probability 1 and every other strategy with probability 0.

A totally mixed strategy is a mixed strategy in which the player assigns a strictly positive probability to every pure strategy. (Totally mixed strategies are important for equilibrium refinement such as trembling hand perfect equilibrium.)

%=================================%


\subsection{What is a pure strategy?}

A pure strategy is an unconditional, defined choice that a person makes in a situation or game. For example, in the game of Rock-Paper-Scissors,if a player would choose to only play scissors for each and every independent trial, regardless of the other player’s strategy, choosing scissors would be the player’s pure strategy. The probability for choosing scissors equal to 1 and all other options (paper and rock) is chosen with the probability of 0. The set of all options (i.e. rock, paper, and scissors) available in this game is known as the strategy set.

%==================================================%

\subsection{What is a mixed strategy?}
\begin{itemize}
\item A mixed strategy is an assignment of probability to all choices in the strategy set. Using the example of Rock-Paper-Scissors, if a person’s probability of employing each pure strategy is equal, then the probability distribution of the strategy set would be 1/3 for each option, or approximately 33\%. In other words, a person using a mixed strategy incorporates more than one pure strategy into a game.

\item The definition of a mixed strategy does not rule out the possibility for an option(s)to never be chosen (eg. pscissors= 0.5, prock = 0.5, ppaper = 0). This means that in a way, a pure strategy can also be considered a mixed strategy at its extreme, with a binary probability assignment (setting one option to 1 and all others equal to 0). For this article, we shall say that pure strategies are not mixed strategies.
\end{itemize}
%==================================================%

\begin{framed}
\noindent \textbf{Pure and Mixed Strategies}


\begin{itemize}
\item A pure strategy determines all your moves during the game (and should therefore specify your moves for all possible other players' moves). 
\item A mixed strategy is a probability distribution over all possible pure strategies (some of which may get zero weight).
\end{itemize}
\end{framed}
%==================================================%


%=================================%


%%- https://cs.stanford.edu/people/eroberts/courses/soco/projects/1998-99/game-theory/Minimax.html

\section{Strategies of Play}
The Minimax algorithm is the most well-known strategy of play of two-player, zero-sum games. The minimax theorem was proven by John von Neumann in 1928. Minimax is a strategy of always minimizing the maximum possible loss which can result from a choice that a player makes. Before we examine minimax, though, let's look at some of the other possible algorithms.

\subsection{Maximax}

The Maximax principle advises the player to choose the strategy that yields the best of the best possible outcomes. For example, let's consider a zero-sum game where two players simultaneously put either a blue or a red card on the table. 
\begin{itemize}
\item If player 1 puts a red card down on the table, whichever card player 2 puts down, no one wins anything.
\item If player 1 puts a blue card on the table and player 2 puts a red card, then player 2 wins \$1,000 from player 1.
\item Finally, if player 1 puts a blue card on the table and player 2 puts a blue card down, then player 1 wins \$1,000 from player 2.
\end{itemize}

The payoff matrix for player 1 is shown in this table:


	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
				\cline{3-4}
				\multicolumn{2}{c|}{} &   Red      &  Blue      \\
				\cline{2-4}
				\multirow{2} {*} {{\color{red}Player 1}}& Red & 1,000 & 0 \\
				\cline{2-4}
				& Blue &-1,000 & 0 \\
				\cline{2-4}
			
			\end{tabular}
		}
	\end{center}

Going by maximax principle, player 1 will always play the blue card, since it has the maximum possible payoff of 1,000. But as can be clearly seen from the table, assuming player 2 is rational, he will never play the blue card, since the red card gives him the dominant strategy. In such a case, if player 1 plays by the maximax rule, he will always lose.

The maximax principle is inherently irrational, as it does not take into account the other player's possible choices. Maximax is often adopted by naive decision-makers such as young children.


\subsection{Maximin}

Maximin is solely a one-person game strategy, i.e. a principle which may be used when a person's "competition" is nature, or chance. Whereas the maximax principle is ultra-optimistic, expecting the best possible payoff, the maximin is ultra-pessimistic, expecting the worst possible payoff. It involves choosing the best of the worst possible outcomes.

A simple example of a slot machine game may be used. A player has only two choices to make -- to gamble or not to gamble. If he gambles, he risks losing his bet (say, $1), but also has a chance to win the maximum payoff (say, $10,000). If he does not gamble, he can neither win nor lose.

The payoff matrix looks like this:

	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
				\cline{3-4}
				\multicolumn{2}{c|}{} &  Gamble      &  Not Gamble     \\
				\cline{2-4}
				\multirow{2} {*} {{\color{red}Player 1}}& Not Gamble & 10,000 & 0 \\
				\cline{2-4}
				& Not Gamble &-1 & 0 \\
				\cline{2-4}
			
			\end{tabular}
		}
	\end{center}

According to the maximin principle, the player should never gamble, because he faces a risk of losing \$1. It is clear that the maximin principle is quite inefficient, since it discourages taking any risks, no matter how high the reward may be.


\subsection{Minimax for One-Person Games}

The Minimax Regret Principle is based on the Minimax Theorem advanced by John von Neumann, but is geared only towards one-person games. It relies on the concept of regret matrices. To demonstrate, consider an example of a company trying to decide whether or not it should support a research project. Let's assume that the research project costs c units. If it succeeds, it will bring in a return of r units. If it fails, it will obviously not bring in anything.

The payoff matrix for the company looks like this:

Research
Succeeds

Fails

Company

Supports research

r - c

-c

Neglect research

0

0


	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
				\cline{3-4}
				\multicolumn{2}{c|}{} &  Gamble      &  Not Gamble     \\
				\cline{2-4}
				\multirow{2} {*} {{\color{red}Player 1}}& Not Gamble & 10,000 & 0 \\
				\cline{2-4}
				& Not Gamble &-1 & 0 \\
				\cline{2-4}
			
			\end{tabular}
		}
	\end{center}

By the maximax principle, a company should always support research if the expected return on it is greater than its cost. By maximin, the company should never support research, since it is risking the cost of the research. Minimax is slightly more complicated.

We need to come up with a matrix that shows the "opportunity cost," or regret, of the player, depending on each possible decision. For example, if the company supports the research and it fails, the company's regret will be c, the price of research. If the company supports the research and it succeeds, the company will have no regrets. If the company neglects research and it would have succeeded, its regret value is r-c, the return on the research. So, the minimax regret matrix will look like this:

Research
Succeeds

Fails

Company

Supports research

0

c

Neglect research

r-c

0


	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
				\cline{3-4}
				\multicolumn{2}{c|}{} &  Gamble      &  Not Gamble     \\
				\cline{2-4}
				\multirow{2} {*} {{\color{red}Player 1}}& Not Gamble & 10,000 & 0 \\
				\cline{2-4}
				& Not Gamble &-1 & 0 \\
				\cline{2-4}
			
			\end{tabular}
		}
	\end{center}

The object is to minimize the maximum possible regret. It is not obvious from the above matrix what the maximum value is. That is, is c greater than r-c? If (r-c) > c, the company should support research. If (r-c) < c, the company should not. In other words, the company should support research if c < r/2, or, if the expected return on research is more than twice its cost.

\section{Minimax for Two-Person Games}

In a two-person, zero-sum game, a person can win only if the other player loses. No cooperation is possible. Andrew Colman's Game Theory and Experimental Games shows the following historical example:

In 1943, the Allied forces received reports that a Japanese convoy would be heading by sea to reinforce their troops. The convoy could take on of two routes -- the Northern or the Southern route. The Allies had to decide where to disperse their reconnaissance aircraft -- in the north or the south -- in order to spot the convoy as early as possible. The following payoff matrix shows the possible decisions made by the Japanese and the Allies, with the outcomes expressed in the number of days of bombing the Allies could achieve with each possibility:


	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Allied}} \\
				\cline{3-4}
				\multicolumn{2}{c|}{} &   North      &  South      \\
				\cline{2-4}
				\multirow{2} {*} {{\color{red}Japanese}}& North & 2 & 1 \\
				\cline{2-4}
				& South &1   & 3 \\
				\cline{2-4}
			
			\end{tabular}
		}
	\end{center}
\begin{itemize}
\item By this matrix, if the Japanese chose to take the southern route while the Allies decided to focus their recon planes in the north, the convoy would be bombed for 2 days. The best outcome for the Allies would be if they placed their airplanes in the south and the Japanese took the southern route. The best outcome for the Japanese would be to take the northern route, provided the Allies were looking for them in the south.

\item To minimize the worst possible outcome, the Allies would have to choose the north as the focus of their reconnaisance efforts. This ensures them 2 days of bombing, whereas they risk only 1 day of bombing if they focus on the south. Therefore, by minimax, the best strategy for them would be to focus on the north.

\item The Japanese can use the same strategy. The worst possible outcome for them is the 3 days of bombing which might occur if they took the southern route. Therefore, the Japanese would take the northern route.

\item It is, in fact, what had occurred: both the Allies and the Japanese chose the north, and the Japanese convoy was bombed for 2 days.

\item The previous matrix had a saddle point, meaning that both the Japanese and the Allies settled on the (North, North) square as the best outcome for both of them. Neither could do any better if the opponent was rational. In this case, the maximin and the minimax strategies produce the same result. Notice that if the Allies were following maximax, they would choose the South, and surely forfeit one day of bombing.
\end{itemize}

\subsection{Mixed Strategies and Randomization}

In some cases, there is no saddle point, and the players have to choose their strategies with a degree of randomness, as in the following simple game, called "\textbf{\textit{Matching Pennies}}". Two players simultaneously place a penny on a table, either heads up or tails up. If the pennies are facing the same way, player 1 gets to keep both pennies. Otherwise, player 2 gets to keep both. The payoff matrix for player 1 looks like this:


	\begin{center}
		{\color{blue}
			\begin{tabular}{c|c|c|c|}
				\multicolumn{2} {c} {} & \multicolumn{2}{c} {{\color{red}Player 2}} \\
				\cline{3-4}
				\multicolumn{2}{c|}{} &   Heads      &  Tails      \\
				\cline{2-4}
				\multirow{2} {*} {{\color{red}Player 1}}& Heads & 1 & -1 \\
				\cline{2-4}
				& Tails &-1& 1 \\
				\cline{2-4}
			
			\end{tabular}
		}
	\end{center}

\begin{itemize}
\item There is no clearly defined strategy for each player. The best way to play is to choose the position of the coin randomly. If either player follows this strategy, then in the long run, the payoffs for each will be 0. 
\item Notice that if, say, player 1 uses a 50/50 strategy, while player 2 plays heads 75\% of the time, in the long run, both players will still have payoffs of 0.
\item  But if player 2 follows the 75/25 strategy, then player 1 can easily take advantage of it by playing heads more frequently, and therefore winning more frequently. So, it is important for each player to not only maintain a random strategy, but to also analyze the strategy of the other player.
\end{itemize}
%========================================%
\subsection{Applications to Computing}
\begin{itemize}
\item In computer simulations for cases such as this, it is important not to program the computer with a specific strategy in advance, but let it decide it at run-time. If the computer does not maintain unpredictability, then the opposing player may use this knowledge to his advantage. Many computer games suffer because although the computer is programmed with a strong strategy, it becomes predictable and easy to take advantage of.
\item 
On the other hand, the computer might very well benefit if it recognizes a predictable strategy on the part of an opponent. Even in such a simple game as "Matching Pennies," where a 50/50 is called for, while the computer may follow a 50\% algorithm for deciding whether to play heads or tails, a human cannot come up with completely random numbers. In fact, it has been observed that humans tend to play heads slightly more often. If a computer recognizes that the probability of its opponent of picking heads is slightly higher, it may adjust its own strategy to have an advantage.
\end{itemize}
\newpage
\section{Minimax}
%%- https://brilliant.org/wiki/minimax/
\begin{itemize}
\item minimax is a decision rule used to minimize the worst-case potential loss; in other words, a player considers all of the best opponent responses to his strategies, and selects the strategy such that the opponent's best strategy gives a payoff as large as possible.
\item 
The name "minimax" comes from minimizing the loss involved when the opponent selects the strategy that gives maximum loss, and is useful in analyzing the first player's decisions both when the players move sequentially and when the players move simultaneously. In the latter case, minimax may give a Nash equilibrium of the game if some additional conditions hold.
\item 
Minimax is also useful in combinatorial games, in which every position is assigned a payoff. The simplest example is assigning a "1" to a winning position and "-1" to a losing one, but as this is difficult to calculate for all but the simplest games, intermediate evaluations (specifically chosen for the game in question) are generally necessary. In this context, the goal of the first player is to maximize the evaluation of the position, and the goal of the second player is to minimize the evaluation of the position, so the minimax rule applies. This, in essence, is how computers approach games like chess and Go, though various computational improvements are possible to the "naive" implementation of minimax.
\end{itemize}
Contents

Formal definition
Minimax theorem
In combinatorial games
See Also
Formal definition
%==========================%
Suppose player  chooses strategy , and the remaining players choose the strategy profile . If  denotes the utility function for player on strategy profile , the minimax of a game is defined as


Intuitively speaking, the minimax (for player ) is one of two equivalent formulations:

The minimax is the smallest value that the other players can force player  to receive, without knowing player 's strategy
The minimax is the largest value player  can guarantee when he is told the strategies of all other players.
Similarly, the maximin is defined as


which can be intuitively understood as either of:

The maximin is the largest value player  can guarantee when he does not know the strategies of any other player
The maximin is the smallest value the other players can force player  to receive, without knowing player 's strategy
For example, consider the following payoff matrix (the rows represent the first player's choices and the columns represent the second player's choices):


\begin{tabular}{|c|c|c|c|}
    &  1   &	2   &	3 \\
1   &	-1 &	-2  &	-1 \\
2   &  	2 &	2   &	1 \\
3   &	-1 &	-1  &	0 \\
\end{tabular}
where both players have a choice between three strategies. In such a payoff matrix, from the first player's perspective:

\begin{itemize}
\item The maximin is the largest of the smallest values in each row
\item The minimax is the smallest of the largest values in each column
\end{itemize}
so the maximin is the largest of -2, 1, and -1 (i.e. 1), and the minimax is the smaller of 2, 2, and 1 (i.e. 1).

It is extremely important to note that

i.e. the maximin is always at most the minimax.
This can be intuitively understood by noting that in minimax, player  effectively gets to choose his strategy after learning everyone else's, which can only increase his payoff.

In the above example, the maximin and the minimax are in fact equal. In such a case (which does not always happen!), the minimax strategy for both players gives a Nash equilibrium of the game.

This is especially important in zero-sum games, in which the minimax always gives a Nash equilibrium of the game, as the minimax and maximin are necessarily equal.
\subsection{Minimax theorem}
The minimax theorem establishes conditions on when the minimax and maximin of a function are equal. More precisely, the minimax theorem gives conditions on when


Formally,

Minimax theorem:

Let  be two compact convex sets, and  be a continuous function on pairs . If  is convex-concave, i.e.

 is convex for all fixed 
 is concave for all fixed 
then

The application of the minimax theorem to zero-sum games is especially important, as it becomes equivalent to

For a zero-sum game with finitely many strategies, there exists a payoff  and a mixed strategy for each player such that
\begin{itemize}
\item Player 1 can achieve a payoff of at most , even given player 2's strategy
\item Player 2 can achieve a payoff of at most , even given player 1's strategy
\end{itemize}
which is equivalent to establishing a Nash equilibrium.
It is important to note that the minimax strategy may be mixed; in general,

It is not necessarily the case that the pure minimax strategy for each player leads to a Nash equilibrium.
For example, consider the payoff matrix
\begin{tabular}{|c|c|c|c|}
   & 1	 & 2	& 3   \\
1  &	3&	-2 &	2 \\
2  &	-1&	0 &	4 \\
3  &	-4&	-3 &	1 \\
\end{tabular}
The minimax choice for the first player is strategy 2, and the minimax choice for the second player is also strategy 2. But both players choosing strategy 2 does not lead to a Nash equilibrium; either player would choose to change their strategy given knowledge of the other's. In fact, the mixed minimax strategies of:
\begin{itemize}
\item Player 1 chooses strategy 1 with probability  and strategy 2 with probability 
\item Player 2 chooses strategy 1 with probability  and strategy 2 with probability 
\end{itemize}
is stable and represents a Nash equilibrium.
In combinatorial games
\end{document}
