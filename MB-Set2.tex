\documentclass{article}
\usepackage{multirow,array}
\begin{document}


  \begin{table}
    \setlength{\extrarowheight}{2pt}
    \begin{tabular}{cc|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
      \multirow{2}*{Player $X$}  & $A$ & $(x,y)$ & $(x,y)$ \\\cline{3-4}
      & $B$ & $(x,y)$ & $(x,y)$ \\\cline{3-4}
    \end{tabular}
  \end{table}


\begin{itemize}
\item Minimax (sometimes MinMax or MM) is a decision rule used in  game theory for minimizing the possible loss for a worst case (maximum loss) scenario. 
\item Originally formulated for two-player zero-sum game theory, covering both the cases where players take alternate moves and those where they make simultaneous moves, it has also been extended to more complex games and to general decision-making in the presence of uncertainty.
\end{itemize}

%=================================================%
\subsection{Minimax Game Solution}
\begin{itemize}
\item An alternative to “solving ” matrix games using the concept of Nash Equilibrium is the
Minimax approach. 
\item It was originally devised for 2-player “Zero Sum” or “Constant Sum”
games where what one player gains the other player loses. 
\item Each player attempts to maximise
hir payoff assuming that hir opponent is attempting to minimise it.
\end{itemize}

Consider the constant sum game
Player 2
Left Right
Player 1 Up (5,3) (2,6)
Down (3,5) (4,4)


  \begin{table}
    \setlength{\extrarowheight}{2pt}
    \begin{tabular}{cc|c|c|}
      & \multicolumn{1}{c}{} & \multicolumn{2}{c}{Player $Y$}\\
      & \multicolumn{1}{c}{} & \multicolumn{1}{c}{$A$}  & \multicolumn{1}{c}{$B$} \\\cline{3-4}
      \multirow{2}*{Player $X$}  & $A$ & $(x,y)$ & $(x,y)$ \\\cline{3-4}
      & $B$ & $(x,y)$ & $(x,y)$ \\\cline{3-4}
    \end{tabular}
  \end{table}



As usual we’ll use the notation R1hs1, s2i and R2hs1, s2i to stand for the payoffs to Player
1 and 2 respectively when Player 1 plays strategy s1 and Player 2 strategy s2. Again let p
be the probability that Player 1 plays Up, and q the probability that Player 2 plays Left.
Then the payoff to player 1 is
R1hpUp+(1−p)Down, qLeft+(1−q)Righti = 5pq+2p(1−q)+3(1−p)q+4(1−p)(1−q) = 4pq−2p−q+4
while the payoff to player 2 is
R2hpUp+(1−p)Down, qLeft+(1−q)Righti = 3pq+6p(1−q)+5(1−p)q+4(1−p)(1−q) = −4pq+2p+q+4
(Note the constant sum R1h·, ·i + R2h·, ·i = 8)

\subsection{Analysis}
If R1 is an increasing function of q (i.e. ∂R1
∂q > 0) then Player 2 minimises Player 1’s
payoff by choosing q = 0. If R1 is an decreasing function of q (i.e. ∂R1
∂q < 0) then Player
2 minimises Player 1’s payoff by choosing q = 1. If however ∂R1
∂q = 0 then Player 2 can’t
influence Player 1’s payoff.

In this case ∂R1
∂q = 4p − 1. Thus
(i) 4p − 1 > 0 ⇒ q = 0 and
R1 = 4 − 2p < 4 − 2(1/4) = 3.5
(ii) 4p − 1 < 0 ⇒ q = 1 and
R1 = 3 + 2p < 3 + 2(1/4) = 3.5
(iii) 4p − 1 = 0 then irrespective of q
R1 = 3.5

%--------------------------------------%

Hence Player 1 should choose p = 1/4 as hir optimal strategy, and v1 = 3.5 .
A similar analysis can be done with R2 as a function of p. Here ∂R2
∂p = −4q + 2. Thus
(i) −4q + 2 > 0 ⇒ p = 0 and
R2 = 4 + q < 4 + 1/2 = 4.5
(ii) −4q + 2 < 0 ⇒ p = 1 and
R2 = 6 − 3q < 6 − 3(1/2) = 4.5
(iii) −4q + 2 = 0 then irrespective of p
R2 = 4.5
Hence Player 2 should choose q = 1/2 as hir optimal strategy, and v2 = 4.5
The minimax strategies are thus h(1/4)Up + (3/4)Down,(1/2)Left + (1/2)Righti.


\end{document}
